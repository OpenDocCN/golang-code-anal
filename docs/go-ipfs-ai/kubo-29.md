# go-ipfs æºç è§£æ 29

# `/opt/kubo/core/node/dns.go`

è¯¥ä»£ç æ˜¯ä¸€ä¸ªåœ¨ Node.js ä¸­ä½¿ç”¨çš„åº“ï¼Œå®ƒçš„ç›®çš„æ˜¯æä¾› DNS è§£æåŠŸèƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒå®ç°äº†ä»¥ä¸‹åŠŸèƒ½ï¼š

1. å®šä¹‰äº†ä¸€ä¸ª DNSResolver å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€ä¸ªé…ç½®å¯¹è±¡ï¼ˆConfigï¼‰å’Œä¸€ä¸ª DNS é€‰é¡¹é…ç½®å¯¹è±¡ï¼ˆOptionsï¼‰ï¼Œç„¶åè¿”å›ä¸€ä¸ª MadNS è§£æå™¨å®ä¾‹å’Œä¸€ä¸ªé”™è¯¯ã€‚
2. åœ¨ DNSResolver å‡½æ•°ä¸­ï¼Œé¦–å…ˆå®šä¹‰äº†ä¸€äº›å˜é‡å’Œå¸¸é‡ï¼ŒåŒ…æ‹¬ï¼š`math.MaxUint32`ã€`time.Second` å’Œ `time.Duration`ï¼Œå®ƒä»¬ç”¨äºè®¾ç½® DNS è§£æçš„æœ€å¤§å¹´é¾„ã€è§£æè¶…æ—¶å’Œè§£æå»¶è¿Ÿã€‚
3. å¦‚æœé…ç½®å¯¹è±¡ä¸­æ²¡æœ‰è®¾ç½® `DNS.MaxCacheTTL` é€‰é¡¹çš„é»˜è®¤å€¼ï¼Œåˆ™æ·»åŠ äº†ä¸€ä¸ª `doh.WithMaxCacheTTL` é€‰é¡¹ï¼Œè®¾ç½®äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„ TTL é€‰é¡¹ã€‚
4. åˆ›å»ºäº†ä¸€ä¸ª `gateway.NewDNSResolver` å®ä¾‹ï¼Œè¯¥å®ä¾‹ä½¿ç”¨äº†ä¸€ä¸ª DNS è§£æå™¨ï¼Œè¯¥å®ä¾‹è®¾ç½®äº†ä¸€ä¸ªè§£æå™¨é€‰é¡¹ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸Šé¢å®šä¹‰çš„é€‰é¡¹ã€‚
5. è¿”å›äº†ä¸€ä¸ª `madns.Resolver` å®ä¾‹å’Œä¸€ä¸ªé”™è¯¯ï¼Œè¯¥é”™è¯¯å¯èƒ½æ˜¯ç”±äºè§£æå™¨è®¾ç½®çš„é€‰é¡¹ä¸æ­£ç¡®ã€ç½‘ç»œè¿æ¥ä¸ç¨³å®šæˆ–è€… DNS æœåŠ¡å™¨ä¸å¯ç”¨ç­‰åŸå› ã€‚


```
package node

import (
	"math"
	"time"

	"github.com/ipfs/boxo/gateway"
	config "github.com/ipfs/kubo/config"
	doh "github.com/libp2p/go-doh-resolver"
	madns "github.com/multiformats/go-multiaddr-dns"
)

func DNSResolver(cfg *config.Config) (*madns.Resolver, error) {
	var dohOpts []doh.Option
	if !cfg.DNS.MaxCacheTTL.IsDefault() {
		dohOpts = append(dohOpts, doh.WithMaxCacheTTL(cfg.DNS.MaxCacheTTL.WithDefault(time.Duration(math.MaxUint32)*time.Second)))
	}

	return gateway.NewDNSResolver(cfg.DNS.Resolvers, dohOpts...)
}

```

# `/opt/kubo/core/node/graphsync.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º "node" çš„åŒ…ï¼Œå®ƒå¯¼å…¥äº†ä»¥ä¸‹ä¾èµ–é¡¹ï¼š

- blockstoreï¼šä¸€ä¸ªåä¸º "blockstore" çš„ blockingå­˜å‚¨åº“ï¼Œæä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„ç‚¹å¯¹ç‚¹å—å­˜å‚¨æœåŠ¡ã€‚
- graphsyncï¼šä¸€ä¸ªåä¸º "graphsync" çš„å¼‚æ­¥å›¾å½¢æ•°æ®ç»“æ„å­˜å‚¨åº“ï¼Œæä¾›äº†é«˜å¯ç”¨æ€§å’Œå¯æ‰©å±•æ€§çš„å›¾å½¢æ•°æ®ç»“æ„ã€‚
- gsimplï¼šä¸€ä¸ªåä¸º "gsimpl" çš„å®ç°äº† "graphsync" åº“çš„ "implementation"ï¼Œå…·ä½“å®ç°å¯èƒ½å› ä¸ªåˆ«äººå·¥æ™ºèƒ½è€Œå¼‚ã€‚
- networkï¼šä¸€ä¸ªåä¸º "network" çš„ç”¨äºç®¡ç†èŠ‚ç‚¹ç½‘ç»œè¿æ¥çš„ "Network" ç±»å‹ï¼Œæä¾›äº†ä¸ IPFS ç½‘ç»œçš„äº¤äº’ã€‚
- libp2pï¼šä¸€ä¸ªåä¸º "libp2p" çš„é«˜æ€§èƒ½çš„ "libp2p" API å®ç°ï¼Œæä¾›äº†ä¸€äº›è·¨å¹³å°çš„æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€‚
- storeutilï¼šä¸€ä¸ªåä¸º "storeutil" çš„è¾…åŠ©å‡½æ•°ï¼Œæä¾›äº†å¯¹ Graphsync å­˜å‚¨åº“çš„ "util" å‡½æ•°ã€‚
- helpersï¼šä¸€ä¸ªåä¸º "helpers" çš„ç”¨äºç®¡ç† Kubernetes å‘½åç©ºé—´å¸®åŠ©ersçš„ "Helpers" ç±»å‹ã€‚

è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯å®šä¹‰äº†ä¸€ä¸ª Graphsync èŠ‚ç‚¹å­˜å‚¨åº“ï¼Œå¹¶å®ç°äº†ä¸ libp2p é€šä¿¡çš„å—å­˜å‚¨å’Œ Graphsync å­˜å‚¨åº“çš„äº¤äº’ã€‚è¿™ä¸ª Graphsync èŠ‚ç‚¹å­˜å‚¨åº“å¯ä»¥åœ¨ IPFS ç½‘ç»œä¸­æä¾›é«˜åº¦å¯é æ€§çš„å—å­˜å‚¨ï¼Œå¹¶æ”¯æŒå¼‚æ­¥æ“ä½œï¼Œæä¾›äº†é«˜æ€§èƒ½çš„å›¾å½¢æ•°æ®ç»“æ„å­˜å‚¨ã€‚


```
package node

import (
	blockstore "github.com/ipfs/boxo/blockstore"
	"github.com/ipfs/go-graphsync"
	gsimpl "github.com/ipfs/go-graphsync/impl"
	"github.com/ipfs/go-graphsync/network"
	"github.com/ipfs/go-graphsync/storeutil"
	libp2p "github.com/libp2p/go-libp2p/core"
	"go.uber.org/fx"

	"github.com/ipfs/kubo/core/node/helpers"
)

// Graphsync constructs a graphsync
```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º "Graphsync" çš„å‡½æ•° "Graphsync"ï¼Œè¯¥å‡½æ•°æ¥å—å››ä¸ªå‚æ•°ï¼šä¸€ä¸ªç”Ÿå‘½å‘¨æœŸï¼ˆLCï¼‰å¯¹è±¡ã€ä¸€ä¸ª MetricsContext å¯¹è±¡ã€ä¸€ä¸ªä¸»æœºï¼ˆhostï¼‰å’Œä¸€ä¸ªå—å­˜å‚¨å™¨ï¼ˆblockstoreï¼‰ã€‚å‡½æ•°çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ª GraphExchange å¯¹è±¡ï¼Œè¯¥å¯¹è±¡ç”¨äºä¸åŒºå—é“¾è¿›è¡Œäº¤äº’ã€‚ä»¥ä¸‹æ˜¯å‡½æ•°çš„è¯¦ç»†è§£é‡Šï¼š

1. é¦–å…ˆï¼Œå‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªåä¸º "ctx" çš„ä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œè¿™ä¸ªä¸Šä¸‹æ–‡å¯¹è±¡ä½¿ç”¨äº† helpers.LifecycleCtx å‡½æ•°å’Œä¸€ä¸ªåä¸º "mctx" çš„ MetricsContext å¯¹è±¡ã€‚è¿™äº›ä¸Šä¸‹æ–‡å¯¹è±¡ç”¨äºåœ¨å‡½æ•°è°ƒç”¨æ—¶ç®¡ç† GraphExchange å¯¹è±¡çš„ç”Ÿå‘½å‘¨æœŸã€‚

2. æ¥ä¸‹æ¥ï¼Œå‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªåä¸º "network" çš„ç½‘ç»œå¯¹è±¡ï¼Œè¿™ä¸ªç½‘ç»œå¯¹è±¡ä½¿ç”¨äº† libp2p.Host å‡½æ•°å’Œä¸€ä¸ªåä¸º "bs" çš„ BlockStorage å¯¹è±¡ã€‚è¿™äº›å¯¹è±¡å°†åœ¨å‡½æ•°ä¸­ç”¨äºä¸åŒºå—é“¾çš„äº¤äº’ã€‚

3. æœ€åï¼Œå‡½æ•°ä½¿ç”¨ gsimpl.New å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ª GraphExchange å¯¹è±¡ã€‚è¿™ä¸ª GraphExchange å¯¹è±¡åŒ…å«äº†ä¸€äº›ç”¨äºä¸åŒºå—é“¾äº¤äº’çš„æ–¹æ³•ï¼Œå¦‚ "ListBlock" å’Œ "ListChainç©ºé—´" æ–¹æ³•ã€‚

æ€»çš„æ¥è¯´ï¼ŒGraphsync å‡½æ•°çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªå¯ä»¥ä¸åŒºå—é“¾è¿›è¡Œäº¤äº’çš„ GraphExchange å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å¯ä»¥åœ¨ä¸æ³„éœ²ä»»ä½•å®ç°ç»†èŠ‚çš„æƒ…å†µä¸‹ä¸åŒºå—é“¾è¿›è¡Œé€šä¿¡ã€‚


```
func Graphsync(lc fx.Lifecycle, mctx helpers.MetricsCtx, host libp2p.Host, bs blockstore.GCBlockstore) graphsync.GraphExchange {
	ctx := helpers.LifecycleCtx(mctx, lc)

	network := network.NewFromLibp2pHost(host)
	return gsimpl.New(ctx, network,
		storeutil.LinkSystemForBlockstore(bs),
	)
}

```

# `/opt/kubo/core/node/groups.go`

è¯¥ä»£ç çš„ä½œç”¨æ˜¯å®šä¹‰äº†ä¸€ä¸ªåä¸º "node" çš„åŒ…ï¼Œå…¶ä¸­å®šä¹‰äº†ä¸€äº›å¯ä»¥ç”¨äºç®¡ç†èŠ‚ç‚¹å·¥å…·çš„å‡½æ•°å’Œå˜é‡ã€‚

å…·ä½“æ¥è¯´ï¼Œè¯¥åŒ…å®šä¹‰äº†ä»¥ä¸‹å‡ ä¸ªå‡½æ•°å’Œå˜é‡ï¼š

- `util.F humanize.String(value) string`ï¼šå°†ä¸€ä¸ªå­—ç¬¦ä¸²å€¼è½¬æ¢ä¸ºå…·æœ‰ "human-readable" æ ·å¼çš„å­—ç¬¦ä¸²ã€‚
- `blockstore.Declareæ”»å‡»è€…è€…æ›¼å“ˆé¡¿ off")`ï¼šä½¿ç”¨ IPFS ä¸­çš„ boxo åº“ä¸­çš„ blockstore ç±»å‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿã€‚
- `blockstore.OpenRç½®ä¿¡è¾¹æ–‡ä»¶ç³»ç»Ÿ](/blockstore.OpenRç½®ä¿¡è¾¹æ–‡ä»¶ç³»ç»Ÿ)`ï¼šä½¿ç”¨ boxo åº“ä¸­çš„ blockstore ç±»å‹æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿã€‚
- `blockstore.OpenRç½®ä¿¡è¾¹æ–‡ä»¶ç³»ç»Ÿ](/blockstore.OpenRç½®ä¿¡è¾¹æ–‡ä»¶ç³»ç»Ÿ)`ï¼šä½¿ç”¨ boxo åº“ä¸­çš„ blockstore ç±»å‹æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿã€‚
- `uio.Readdir`, `uio.WriteFile`ï¼šæä¾›äº†ä¸€äº›é€šç”¨çš„æ–‡ä»¶ I/O æ“ä½œã€‚
- `libp2p.PunlockAlliance oneself thetaé¼“åŠ±æ€](/libp2p.PunlockAlliance oneself thetaé¼“åŠ±æ€)`ï¼šä½¿ç”¨ IPFS ä¸­çš„ libp2p-pubsub åº“å®ç° pubsub å®¢æˆ·ç«¯ã€‚
- `libp2p.MutualExclusion MutualExclusion`ï¼šå®ç° IPFS ä¸­çš„ libp2p-pubsub åº“ä¸­çš„ MutualExclusionã€‚
- `libp2p.Queryingä¸æ›¾æœ‰å®é™…å€¼`, `libp2p.Pè€å¿ƒæŒä¹…åœ°è¿›è¡ŒæŸ¥è¯¢`ï¼šå®ç° IPFS ä¸­çš„ libp2p-pubsub åº“ä¸­çš„ Queryingã€‚
- `libp2p.TLStså¤ªé˜³å…‰çº¿ libp2p.TLSts`ï¼šå®ç° IPFS ä¸­çš„ libp2p-tls åº“ä¸­çš„ TLSã€‚
- `pubsub.Gæ­¦å¾· deéª‘çƒ½ç«å°æ–‡æœ¬å†…å®¹`ï¼šå®ç° IPFS ä¸­çš„ libp2p-pubsub åº“ä¸­çš„æ–‡æœ¬å‘å¸ƒè€…ã€‚
- `pubsub.Gæ­¦å¾· deéª‘çƒ½ç«å°`ï¼šå®ç° IPFS ä¸­çš„ libp2p-pubsub åº“ä¸­çš„æ–‡æœ¬å‘å¸ƒè€…ã€‚
- `resource-manager.æ›¼å“ˆé¡¿è€…æ›¼å“ˆé¡¿è€…`ï¼šå®ç° IPFS ä¸­çš„ libp2p-host åº“ä¸­çš„èµ„æºç®¡ç†å™¨ã€‚
- `rcmgr.å‚æ‚¬è‰ Grpc`ï¼šå®ç° IPFS ä¸­çš„ libp2p-host åº“ä¸­çš„èµ„æºç®¡ç†å™¨ã€‚


```
package node

import (
	"context"
	"errors"
	"fmt"
	"time"

	"github.com/dustin/go-humanize"
	blockstore "github.com/ipfs/boxo/blockstore"
	offline "github.com/ipfs/boxo/exchange/offline"
	uio "github.com/ipfs/boxo/ipld/unixfs/io"
	util "github.com/ipfs/boxo/util"
	"github.com/ipfs/go-log"
	"github.com/ipfs/kubo/config"
	"github.com/ipfs/kubo/core/node/libp2p"
	"github.com/ipfs/kubo/p2p"
	pubsub "github.com/libp2p/go-libp2p-pubsub"
	"github.com/libp2p/go-libp2p-pubsub/timecache"
	"github.com/libp2p/go-libp2p/core/peer"
	rcmgr "github.com/libp2p/go-libp2p/p2p/host/resource-manager"
	"go.uber.org/fx"
)

```

This is a Rust implementation of the Nettyä½å»¶è¿Ÿç½‘ç»œåº“ä¸­çš„ä¸€ä¸ª`SocketStream`å®ç°ã€‚è¿™ä¸ª`SocketStream`å®ç°æ”¯æŒTCPå’ŒUDPåè®®ï¼Œæä¾›äº†` readFrom`å’Œ`writeTo`æ–¹æ³•æ¥æ¥æ”¶å’Œå‘é€æ•°æ®ã€‚

è¯¥å®ç°ä½¿ç”¨äº†Nettyä¸­çš„`libp2p`åº“ï¼Œå…¶ä¸­åŒ…æ‹¬`libp2p::{Swarm, Relay, Addresses, Transport}}`ç±»ï¼Œä»¥åŠ`libp2p::Result`å’Œå…¶ä»–åº“å‡½æ•°ã€‚

è¯¥å®ç°ä¸­è¿˜åŒ…å«äº†ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œå¦‚`é»„ç“œæŠ€èƒ½`ç­‰ï¼Œç”¨äºå¸®åŠ©å¼€å‘è€…å¤„ç†ç½‘ç»œè¿æ¥ã€è·¯ç”±ã€å®‰å…¨æ€§å’Œå…¶ä»–è®¾ç½®ã€‚


```
var logger = log.Logger("core:constructor")

var BaseLibP2P = fx.Options(
	fx.Provide(libp2p.PNet),
	fx.Provide(libp2p.ConnectionManager),
	fx.Provide(libp2p.Host),
	fx.Provide(libp2p.MultiaddrResolver),

	fx.Provide(libp2p.DiscoveryHandler),

	fx.Invoke(libp2p.PNetChecker),
)

func LibP2P(bcfg *BuildCfg, cfg *config.Config, userResourceOverrides rcmgr.PartialLimitConfig) fx.Option {
	var connmgr fx.Option

	// set connmgr based on Swarm.ConnMgr.Type
	connMgrType := cfg.Swarm.ConnMgr.Type.WithDefault(config.DefaultConnMgrType)
	switch connMgrType {
	case "none":
		connmgr = fx.Options() // noop
	case "", "basic":
		grace := cfg.Swarm.ConnMgr.GracePeriod.WithDefault(config.DefaultConnMgrGracePeriod)
		low := int(cfg.Swarm.ConnMgr.LowWater.WithDefault(config.DefaultConnMgrLowWater))
		high := int(cfg.Swarm.ConnMgr.HighWater.WithDefault(config.DefaultConnMgrHighWater))
		connmgr = fx.Provide(libp2p.ConnectionManager(low, high, grace))
	default:
		return fx.Error(fmt.Errorf("unrecognized Swarm.ConnMgr.Type: %q", connMgrType))
	}

	// parse PubSub config

	ps, disc := fx.Options(), fx.Options()
	if bcfg.getOpt("pubsub") || bcfg.getOpt("ipnsps") {
		disc = fx.Provide(libp2p.TopicDiscovery())

		var pubsubOptions []pubsub.Option
		pubsubOptions = append(
			pubsubOptions,
			pubsub.WithMessageSigning(!cfg.Pubsub.DisableSigning),
			pubsub.WithSeenMessagesTTL(cfg.Pubsub.SeenMessagesTTL.WithDefault(pubsub.TimeCacheDuration)),
		)

		var seenMessagesStrategy timecache.Strategy
		configSeenMessagesStrategy := cfg.Pubsub.SeenMessagesStrategy.WithDefault(config.DefaultSeenMessagesStrategy)
		switch configSeenMessagesStrategy {
		case config.LastSeenMessagesStrategy:
			seenMessagesStrategy = timecache.Strategy_LastSeen
		case config.FirstSeenMessagesStrategy:
			seenMessagesStrategy = timecache.Strategy_FirstSeen
		default:
			return fx.Error(fmt.Errorf("unsupported Pubsub.SeenMessagesStrategy %q", configSeenMessagesStrategy))
		}
		pubsubOptions = append(pubsubOptions, pubsub.WithSeenMessagesStrategy(seenMessagesStrategy))

		switch cfg.Pubsub.Router {
		case "":
			fallthrough
		case "gossipsub":
			ps = fx.Provide(libp2p.GossipSub(pubsubOptions...))
		case "floodsub":
			ps = fx.Provide(libp2p.FloodSub(pubsubOptions...))
		default:
			return fx.Error(fmt.Errorf("unknown pubsub router %s", cfg.Pubsub.Router))
		}
	}

	autonat := fx.Options()

	switch cfg.AutoNAT.ServiceMode {
	default:
		panic("BUG: unhandled autonat service mode")
	case config.AutoNATServiceDisabled:
	case config.AutoNATServiceUnset:
		// TODO
		//
		// We're enabling the AutoNAT service by default on _all_ nodes
		// for the moment.
		//
		// We should consider disabling it by default if the dht is set
		// to dhtclient.
		fallthrough
	case config.AutoNATServiceEnabled:
		autonat = fx.Provide(libp2p.AutoNATService(cfg.AutoNAT.Throttle))
	}

	enableRelayTransport := cfg.Swarm.Transports.Network.Relay.WithDefault(true) // nolint
	enableRelayService := cfg.Swarm.RelayService.Enabled.WithDefault(enableRelayTransport)
	enableRelayClient := cfg.Swarm.RelayClient.Enabled.WithDefault(enableRelayTransport)

	// Log error when relay subsystem could not be initialized due to missing dependency
	if !enableRelayTransport {
		if enableRelayService {
			logger.Fatal("Failed to enable `Swarm.RelayService`, it requires `Swarm.Transports.Network.Relay` to be true.")
		}
		if enableRelayClient {
			logger.Fatal("Failed to enable `Swarm.RelayClient`, it requires `Swarm.Transports.Network.Relay` to be true.")
		}
	}

	// Force users to migrate old config.
	// nolint
	if cfg.Swarm.DisableRelay {
		logger.Fatal("The 'Swarm.DisableRelay' config field was removed." +
			"Use the 'Swarm.Transports.Network.Relay' instead.")
	}
	// nolint
	if cfg.Swarm.EnableAutoRelay {
		logger.Fatal("The 'Swarm.EnableAutoRelay' config field was removed." +
			"Use the 'Swarm.RelayClient.Enabled' instead.")
	}
	// nolint
	if cfg.Swarm.EnableRelayHop {
		logger.Fatal("The `Swarm.EnableRelayHop` config field was removed.\n" +
			"Use `Swarm.RelayService` to configure the circuit v2 relay.\n" +
			"If you want to continue running a circuit v1 relay, please use the standalone relay daemon: https://dist.ipfs.tech/#libp2p-relay-daemon (with RelayV1.Enabled: true)")
	}

	// Gather all the options
	opts := fx.Options(
		BaseLibP2P,

		// identify's AgentVersion (incl. optional agent-version-suffix)
		fx.Provide(libp2p.UserAgent()),

		// Services (resource management)
		fx.Provide(libp2p.ResourceManager(cfg.Swarm, userResourceOverrides)),
		fx.Provide(libp2p.AddrFilters(cfg.Swarm.AddrFilters)),
		fx.Provide(libp2p.AddrsFactory(cfg.Addresses.Announce, cfg.Addresses.AppendAnnounce, cfg.Addresses.NoAnnounce)),
		fx.Provide(libp2p.SmuxTransport(cfg.Swarm.Transports)),
		fx.Provide(libp2p.RelayTransport(enableRelayTransport)),
		fx.Provide(libp2p.RelayService(enableRelayService, cfg.Swarm.RelayService)),
		fx.Provide(libp2p.Transports(cfg.Swarm.Transports)),
		fx.Provide(libp2p.ListenOn(cfg.Addresses.Swarm)),
		fx.Invoke(libp2p.SetupDiscovery(cfg.Discovery.MDNS.Enabled)),
		fx.Provide(libp2p.ForceReachability(cfg.Internal.Libp2pForceReachability)),
		fx.Provide(libp2p.HolePunching(cfg.Swarm.EnableHolePunching, enableRelayClient)),

		fx.Provide(libp2p.Security(!bcfg.DisableEncryptedConnections, cfg.Swarm.Transports)),

		fx.Provide(libp2p.Routing),
		fx.Provide(libp2p.ContentRouting),

		fx.Provide(libp2p.BaseRouting(cfg)),
		maybeProvide(libp2p.PubsubRouter, bcfg.getOpt("ipnsps")),

		maybeProvide(libp2p.BandwidthCounter, !cfg.Swarm.DisableBandwidthMetrics),
		maybeProvide(libp2p.NatPortMap, !cfg.Swarm.DisableNatPortMap),
		libp2p.MaybeAutoRelay(cfg.Swarm.RelayClient.StaticRelays, cfg.Peering, enableRelayClient),
		autonat,
		connmgr,
		ps,
		disc,
	)

	return opts
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºStorageçš„å‡½æ•°ï¼Œå®ƒæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼šæ„å»ºé…ç½®å—ï¼ˆcfgï¼‰å’Œä¸€ä¸ªé…ç½®é€‰é¡¹ï¼ˆbcfgï¼‰ã€‚

Storageå‡½æ•°é€šè¿‡æä¾›ä¸€ç»„é€‰é¡¹ï¼Œå°†datastoreè®¾ç½®ä¸ºåŸºäºæŒä¹…æ€§å’Œå—å­˜å‚¨å±‚çš„å­˜å‚¨ç»„ã€‚å‡½æ•°é¦–å…ˆè®¾ç½®å—å­˜å‚¨é€‰é¡¹ï¼ŒåŒ…æ‹¬Bloomè¿‡æ»¤å™¨å¤§å°ï¼Œç„¶åæ ¹æ®ä¼ å…¥çš„é…ç½®é€‰é¡¹ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼Œæˆ–è®¾ç½®ä¸º0ã€‚

æ¥ä¸‹æ¥ï¼Œå‡½æ•°æ ¹æ®ä¼ å…¥çš„é€‰é¡¹ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼Œæˆ–è®¾ç½®ä¸º0ï¼Œåˆ›å»ºä¸€ä¸ªæœ€ç»ˆå—å­˜å‚¨å™¨ï¼ˆfinalBstoreï¼‰ã€‚

ç„¶åï¼Œå‡½æ•°ä½¿ç”¨æä¾›çš„å‡½æ•°ï¼ŒRepoConfigï¼ŒDatastoreï¼Œå’ŒBaseBlockstoreCtorï¼Œæä¾›ä¸€ç³»åˆ—é€‰é¡¹ï¼Œå°†å—å­˜å‚¨å™¨ï¼ˆfinalBstoreï¼‰ç”¨äºå­˜å‚¨æ•°æ®ã€‚

æœ€åï¼Œå‡½æ•°å°†æä¾›çš„é€‰é¡¹ï¼ˆDatastoreï¼ŒBaseBlockstoreCtorï¼ŒRepoConfigå’Œæä¾›é€‰é¡¹ï¼‰ä½œä¸ºè¿”å›å€¼ã€‚


```
// Storage groups units which setup datastore based persistence and blockstore layers
func Storage(bcfg *BuildCfg, cfg *config.Config) fx.Option {
	cacheOpts := blockstore.DefaultCacheOpts()
	cacheOpts.HasBloomFilterSize = cfg.Datastore.BloomFilterSize
	if !bcfg.Permanent {
		cacheOpts.HasBloomFilterSize = 0
	}

	finalBstore := fx.Provide(GcBlockstoreCtor)
	if cfg.Experimental.FilestoreEnabled || cfg.Experimental.UrlstoreEnabled {
		finalBstore = fx.Provide(FilestoreBlockstoreCtor)
	}

	return fx.Options(
		fx.Provide(RepoConfig),
		fx.Provide(Datastore),
		fx.Provide(BaseBlockstoreCtor(cacheOpts, bcfg.NilRepo, cfg.Datastore.HashOnRead)),
		finalBstore,
	)
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º "Identity" çš„å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯éªŒè¯å¹¶æä¾›ä¸€ä¸ªå…·æœ‰ cryptographic èº«ä»½æ ‡è¯†çš„é€‰é¡¹ã€‚å®ƒæ¥å—ä¸€ä¸ªåä¸º "config" çš„é€‰é¡¹å‚æ•°ï¼Œè¿™æ˜¯ä¸€ä¸ª fx.Option ç±»å‹ã€‚å‡½æ•°çš„å®ç°å¦‚ä¸‹ï¼š
java
func Identity(cfg *config.Config) fx.Option {
	// PeerID
	cid := cfg.Identity.PeerID
	if cid == "" {
		return fx.Error(errors.New("identity was not set in config (was 'ipfs init' run?)"))
	}
	if len(cid) == 0 {
		return fx.Error(errors.New("no peer ID in config! (was 'ipfs init' run?)"))
	}

	id, err := peer.Decode(cid)
	if err != nil {
		return fx.Error(fmt.Errorf("peer ID invalid: %s", err))
	}

	// Private Key
	if cfg.Identity.PrivKey == "" {
		return fx.Options( // No PK (usually in tests)
			fx.Provide(PeerID(id)),
			fx.Provide(libp2p.Peerstore),
		)
	}

	sk, err := cfg.Identity.DecodePrivateKey("passphrase todo!")
	if err != nil {
		return fx.Error(err)
	}

	return fx.Options( // Full identity
		fx.Provide(PeerID(id)),
		fx.Provide(PrivateKey(sk)),
		fx.Provide(libp2p.Peerstore),

		fx.Invoke(libp2p.PstoreAddSelfKeys),
	)
}

é¦–å…ˆï¼Œå‡½æ•°æ£€æŸ¥é…ç½®é€‰é¡¹æ˜¯å¦å·²è®¾ç½®ã€‚å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œå®ƒå°†è¿”å›ä¸€ä¸ªé”™è¯¯ã€‚ç„¶åï¼Œå®ƒéªŒè¯è‡ªå®šä¹‰æ ‡è¯†ç¬¦ "PeerID" æ˜¯å¦å·²è®¾ç½®ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å°è¯•å°†è¯¥æ ‡è¯†ç¬¦è§£æä¸ºå¯¹åº”çš„å®¢æˆ·ç«¯ IDã€‚æ¥ä¸‹æ¥ï¼Œå®ƒéªŒè¯æ˜¯å¦æœ‰ç§é’¥å¹¶å°†å…¶ decodeã€‚ç„¶åï¼Œå®ƒå°è¯•é€šè¿‡è°ƒç”¨ libp2p.PstoreAddSelfKeys å‡½æ•°æ¥éªŒè¯ç§é’¥ã€‚æœ€åï¼Œå®ƒæ ¹æ®éªŒè¯ç»“æœè¿”å›ä¸€ä¸ª fx.Optionã€‚


```
// Identity groups units providing cryptographic identity
func Identity(cfg *config.Config) fx.Option {
	// PeerID

	cid := cfg.Identity.PeerID
	if cid == "" {
		return fx.Error(errors.New("identity was not set in config (was 'ipfs init' run?)"))
	}
	if len(cid) == 0 {
		return fx.Error(errors.New("no peer ID in config! (was 'ipfs init' run?)"))
	}

	id, err := peer.Decode(cid)
	if err != nil {
		return fx.Error(fmt.Errorf("peer ID invalid: %s", err))
	}

	// Private Key

	if cfg.Identity.PrivKey == "" {
		return fx.Options( // No PK (usually in tests)
			fx.Provide(PeerID(id)),
			fx.Provide(libp2p.Peerstore),
		)
	}

	sk, err := cfg.Identity.DecodePrivateKey("passphrase todo!")
	if err != nil {
		return fx.Error(err)
	}

	return fx.Options( // Full identity
		fx.Provide(PeerID(id)),
		fx.Provide(PrivateKey(sk)),
		fx.Provide(libp2p.Peerstore),

		fx.Invoke(libp2p.PstoreAddSelfKeys),
	)
}

```

This is a Go function that configures the IPNS (Inter-Peer DNS) service. It takes in several configuration settings, including the `Repå‡ºç‰ˆç‰©å‘¨æœŸ` (the time period for which the service will automatically republicate), the `Recordå¯¿å‘½` (the lifetime of the records in the DNS store), and the experimental settings for the strategic provider.

The function first checks that the settings are valid and sets the `repubPeriod` and `recordLifetime` variables accordingly. If there are any errors, it returns an error with a message indicating the relevant setting.

The function then sets up the IPNS service, including providing any necessary configurations for the `Bitswap` service, the `OnlineExchange` service, and the `Graphsync` service. It also enables the experimental settings for the `StrategicProviding` and `GraphsyncEnabled` settings.

Finally, the function invokes the `IpnsRepublisher` service to begin the republation of the DNS records, and provides the necessary configurations for the `p2p` and `LibP2P` services.


```
// IPNS groups namesys related units
var IPNS = fx.Options(
	fx.Provide(RecordValidator),
)

// Online groups online-only units
func Online(bcfg *BuildCfg, cfg *config.Config, userResourceOverrides rcmgr.PartialLimitConfig) fx.Option {
	// Namesys params

	ipnsCacheSize := cfg.Ipns.ResolveCacheSize
	if ipnsCacheSize == 0 {
		ipnsCacheSize = DefaultIpnsCacheSize
	}
	if ipnsCacheSize < 0 {
		return fx.Error(fmt.Errorf("cannot specify negative resolve cache size"))
	}

	// Republisher params

	var repubPeriod, recordLifetime time.Duration

	if cfg.Ipns.RepublishPeriod != "" {
		d, err := time.ParseDuration(cfg.Ipns.RepublishPeriod)
		if err != nil {
			return fx.Error(fmt.Errorf("failure to parse config setting IPNS.RepublishPeriod: %s", err))
		}

		if !util.Debug && (d < time.Minute || d > (time.Hour*24)) {
			return fx.Error(fmt.Errorf("config setting IPNS.RepublishPeriod is not between 1min and 1day: %s", d))
		}

		repubPeriod = d
	}

	if cfg.Ipns.RecordLifetime != "" {
		d, err := time.ParseDuration(cfg.Ipns.RecordLifetime)
		if err != nil {
			return fx.Error(fmt.Errorf("failure to parse config setting IPNS.RecordLifetime: %s", err))
		}

		recordLifetime = d
	}

	/* don't provide from bitswap when the strategic provider service is active */
	shouldBitswapProvide := !cfg.Experimental.StrategicProviding

	return fx.Options(
		fx.Provide(BitswapOptions(cfg, shouldBitswapProvide)),
		fx.Provide(OnlineExchange()),
		maybeProvide(Graphsync, cfg.Experimental.GraphsyncEnabled),
		fx.Provide(DNSResolver),
		fx.Provide(Namesys(ipnsCacheSize)),
		fx.Provide(Peering),
		PeerWith(cfg.Peering.Peers...),

		fx.Invoke(IpnsRepublisher(repubPeriod, recordLifetime)),

		fx.Provide(p2p.New),

		LibP2P(bcfg, cfg, userResourceOverrides),
		OnlineProviders(
			cfg.Experimental.StrategicProviding,
			cfg.Reprovider.Strategy.WithDefault(config.DefaultReproviderStrategy),
			cfg.Reprovider.Interval.WithDefault(config.DefaultReproviderInterval),
			cfg.Routing.AcceleratedDHTClient,
		),
	)
}

```

æ­¤ä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º"Offline"çš„é…ç½®é€‰é¡¹ï¼Œè¯¥é€‰é¡¹å°†é€‰ä¸­çš„ Offline æœåŠ¡ä¸åŸºæœ¬ IPFS æœåŠ¡ä¸€èµ·æä¾›ã€‚å®ƒåŒ…æ‹¬ä»¥ä¸‹é€‰é¡¹ï¼š

* `fx.Provide(offline.Exchange)`ï¼šè¿™æ˜¯ Offline æœåŠ¡çš„ä¸»è¦ IPFS  exchange é€‰é¡¹ã€‚
* `fx.Provide(DNSResolver)`ï¼šè¿™æ˜¯ Offline æœåŠ¡çš„ä¸»è¦ DNS è§£æå™¨é€‰é¡¹ã€‚
* `fx.Provide(Namesys(0))`ï¼šè¿™æ˜¯ä¸€ä¸ªå¤‡é€‰çš„è§£æå™¨ï¼Œç”¨äºåœ¨æ— æ³•ä½¿ç”¨ OfflineExchange å’Œ DNSResolver çš„æƒ…å†µä¸­ä½¿ç”¨ã€‚
* `fx.Provide(libp2p.Routing)`ï¼šè¿™æ˜¯ Offline æœåŠ¡çš„ä¸»è¦è·¯ç”±å™¨é€‰é¡¹ã€‚
* `fx.Provide(libp2p.ContentRouting)`ï¼šè¿™æ˜¯ Offline æœåŠ¡çš„ ContentRoutes é€‰é¡¹ã€‚
* `fx.Provide(libp2p.OfflineRouting)`ï¼šè¿™æ˜¯ Offline æœåŠ¡çš„é€‰é¡¹ï¼Œç”¨äºå¯ç”¨æˆ–ç¦ç”¨åœ¨ Offline ç½‘ç»œä¸­ä½¿ç”¨ libp2pã€‚
* `OfflineProviders()`ï¼šè¿™æ˜¯ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºè¿”å› Offline æœåŠ¡çš„å¯ç”¨æä¾›å•†ã€‚

`Core` å˜é‡å®šä¹‰äº†åŸºæœ¬ IPFS æœåŠ¡ï¼ŒåŒ…æ‹¬ä»¥ä¸‹é€‰é¡¹ï¼š

* `fx.Provide(BlockService)`ï¼šè¿™æ˜¯ BlockService é€‰é¡¹ï¼Œç”¨äºå¯ç”¨æˆ–ç¦ç”¨ IPFS ä¸Šçš„ Block æœåŠ¡ã€‚
* `fx.Provide(Dag)`ï¼šè¿™æ˜¯æœ‰åºçš„æ•°æ®ç»“æ„ï¼Œç”¨äºå¯ç”¨æˆ–ç¦ç”¨ IPFS ä¸Šçš„ DAG æœåŠ¡ã€‚
* `fx.Provide(FetcherConfig)`ï¼šè¿™æ˜¯ Fetcher é…ç½®é€‰é¡¹ï¼Œç”¨äºé…ç½® Offline Fetcherã€‚
* `fx.Provide(PathResolverConfig)`ï¼šè¿™æ˜¯è·¯å¾„è§£æå™¨é…ç½®é€‰é¡¹ï¼Œç”¨äºé…ç½® Offline è·¯å¾„è§£æå™¨ã€‚
* `fx.Provide(Pinning)`ï¼šè¿™æ˜¯ IPFS ä¸Šçš„ pin é€‰é¡¹ã€‚
* `fx.Provide(Files)`ï¼šè¿™æ˜¯ File é€‰é¡¹ï¼Œç”¨äºå¯ç”¨æˆ–ç¦ç”¨ IPFS ä¸Šçš„æ–‡ä»¶ç³»ç»Ÿã€‚


```
// Offline groups offline alternatives to Online units
func Offline(cfg *config.Config) fx.Option {
	return fx.Options(
		fx.Provide(offline.Exchange),
		fx.Provide(DNSResolver),
		fx.Provide(Namesys(0)),
		fx.Provide(libp2p.Routing),
		fx.Provide(libp2p.ContentRouting),
		fx.Provide(libp2p.OfflineRouting),
		OfflineProviders(),
	)
}

// Core groups basic IPFS services
var Core = fx.Options(
	fx.Provide(BlockService),
	fx.Provide(Dag),
	fx.Provide(FetcherConfig),
	fx.Provide(PathResolverConfig),
	fx.Provide(Pinning),
	fx.Provide(Files),
)

```

The code you provided is a Rust implementation of the IPFS (InterPlanetary File System) options configuration builder. It appears to be part of a larger IPFS library that provides options for building IPFS groups.

The `Offline` struct appears to be the main entry point for building IPFS groups. It creates a `BuildCfg` object and returns an instance of the `Offline` struct. The `BuildCfg` object is defined by the `BuildCfg` struct, which appears to be a configuration object for IPFS. The `Offline` struct appears to take this configuration object and use it to build a `Group` object that implements the `Group` interface for IPFS.

The `IPFS` struct is defined to build a group of fx Options based on the passed `BuildCfg`. It appears to take a `BuildCfg` object and return an instance of the `IPFS` struct.

The `builders` map appears to map between the `BuildCfg` and `IPFS` structs. It appears to be used to build the IPFS group by passing the `BuildCfg` object to the `IPFS` struct.

The `cfgToOptions` function appears to convert a `BuildCfg` object to fx Options. It takes the `BuildCfg` object as an argument and returns an instance of the `Options` struct. It appears to convert the `BuildCfg` object to the desired IPFS options.

The `useGit` function appears to check if the `Experimental.ShardingEnabled` field is set in the `BuildCfg`. If it is, itä¼¼ä¹ automatically shards the directory block larger than a specified threshold. If it is not set, it appears to restore the old behavior (sharding everything).

The `WithUserResourceOverrides` function appears to get the user resource overrides from the `BuildCfg`. It is not defined in the code provided, but its behavior is not used in the `IPFS` struct.


```
func Networked(bcfg *BuildCfg, cfg *config.Config, userResourceOverrides rcmgr.PartialLimitConfig) fx.Option {
	if bcfg.Online {
		return Online(bcfg, cfg, userResourceOverrides)
	}
	return Offline(cfg)
}

// IPFS builds a group of fx Options based on the passed BuildCfg
func IPFS(ctx context.Context, bcfg *BuildCfg) fx.Option {
	if bcfg == nil {
		bcfg = new(BuildCfg)
	}

	bcfgOpts, cfg := bcfg.options(ctx)
	if cfg == nil {
		return bcfgOpts // error
	}

	userResourceOverrides, err := bcfg.Repo.UserResourceOverrides()
	if err != nil {
		return fx.Error(err)
	}

	// Auto-sharding settings
	shardSizeString := cfg.Internal.UnixFSShardingSizeThreshold.WithDefault("256kiB")
	shardSizeInt, err := humanize.ParseBytes(shardSizeString)
	if err != nil {
		return fx.Error(err)
	}
	uio.HAMTShardingSize = int(shardSizeInt)

	// Migrate users of deprecated Experimental.ShardingEnabled flag
	if cfg.Experimental.ShardingEnabled {
		logger.Fatal("The `Experimental.ShardingEnabled` field is no longer used, please remove it from the config.\n" +
			"go-ipfs now automatically shards when directory block is bigger than  `" + shardSizeString + "`.\n" +
			"If you need to restore the old behavior (sharding everything) set `Internal.UnixFSShardingSizeThreshold` to `1B`.\n")
	}

	return fx.Options(
		bcfgOpts,

		fx.Provide(baseProcess),

		Storage(bcfg, cfg),
		Identity(cfg),
		IPNS,
		Networked(bcfg, cfg, userResourceOverrides),

		Core,
	)
}

```

# `/opt/kubo/core/node/helpers.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `lcProcess` çš„ç±»ï¼Œè¯¥ç±»ä½¿ç”¨äº† `github.com/jbenet/goprocess` å’Œ `github.com/pkg/errors` ä¸¤ä¸ª packagesã€‚è¿™ä¸ªç±»çš„å®ä¾‹ä»£è¡¨äº†ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ gRPC æœåŠ¡ï¼Œä½¿ç”¨äº† gRPC å£°æ˜çš„ ` serve` å‡½æ•°æ¥å¯åŠ¨æœåŠ¡ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™ä¸ªç±»çš„ `fx.In` å­—æ®µè¡¨ç¤ºè¯¥ç±»çš„å®ä¾‹æ¥å—æ¥è‡ªå¤–éƒ¨ gRPC åº”ç”¨ç¨‹åºçš„è¾“å…¥ã€‚ç„¶åï¼Œå®ƒå¯¼å…¥äº†ä¸€ç³»åˆ—æ¥è‡ª `github.com/pkg/errors` å’Œ `github.com/jbenet/goprocess` çš„å¤–è®¾å‡½æ•°ï¼ŒåŒ…æ‹¬ `ctx.Context` å‡½æ•°ç”¨äºè·å–æœåŠ¡å™¨çš„ä¸Šä¸‹æ–‡ï¼Œ`err.Error` å‡½æ•°ç”¨äºå°†ä» ` serve` å‡½æ•°è·å¾—çš„é”™è¯¯ä¿¡æ¯è¿”å›åˆ°å®¢æˆ·ç«¯ï¼Œ`fx.Lifecycle` å‡½æ•°ç”¨äºç®¡ç†è¯¥ç±»çš„å®ä¾‹åœ¨ gRPC åº”ç”¨ç¨‹åºä¸­çš„ lifecycleã€‚

æœ€åï¼Œè¯¥ç±»å®ä¾‹äº†ä¸€ä¸ª `goprocess.Process` ç±»å‹çš„ `Proc` å­—æ®µï¼Œç„¶åä½¿ç”¨ `serve` å‡½æ•°å¯åŠ¨äº†è¯¥è¿›ç¨‹ã€‚è¿™ä¸ªè¿›ç¨‹æ¥æ”¶æ¥è‡ªå¤–éƒ¨ gRPC åº”ç”¨ç¨‹åºçš„è¾“å…¥ï¼Œå¹¶åœ¨è¿è¡Œæ—¶æ‰§è¡ŒæœåŠ¡ã€‚


```
package node

import (
	"context"

	"github.com/jbenet/goprocess"
	"github.com/pkg/errors"
	"go.uber.org/fx"
)

type lcProcess struct {
	fx.In

	LC   fx.Lifecycle
	Proc goprocess.Process
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `Append` çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ª `goprocess.ProcessFunc` ç±»å‹çš„å‚æ•°ï¼Œå°†å…¶åŠ å…¥åˆ°åä¸º `lp` çš„ `LCProcess` å®ä¾‹çš„ `Append` æ–¹æ³•ä¸­ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™æ®µä»£ç æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

1. åˆ›å»ºä¸€ä¸ªåä¸º `proc` çš„ `goprocess.Process` å®ä¾‹ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ° `lp.LC.Append` æ–¹æ³•çš„ç¬¬ä¸€ä¸ªå‚æ•°ä¸­ï¼Œå³ `fx.Hook` ç±»å‹çš„ `OnStart` æ–¹æ³•çš„å›è°ƒä¸­ã€‚
2. åˆ›å»ºä¸€ä¸ªåä¸º `proc` çš„ `goprocess.Process` å®ä¾‹ï¼Œå¹¶å°†å…¶åŠ å…¥åˆ° `lp.LC.Append` æ–¹æ³•çš„ç¬¬äºŒä¸ªå‚æ•°ä¸­ï¼Œå³ `fx.Hook` ç±»å‹çš„ `OnStop` æ–¹æ³•çš„å›è°ƒä¸­ã€‚
3. åœ¨ `OnStop` æ–¹æ³•çš„å›è°ƒä¸­ï¼Œç”±äº `proc` å·²ç»è¢«åˆ›å»ºå¹¶åŠ å…¥åˆ° `lp.LC.Append` æ–¹æ³•ä¸­ï¼Œå› æ­¤å¯ä»¥ç›´æ¥è°ƒç”¨ `proc.Close()` æ–¹æ³•æ¥å…³é—­è¿›ç¨‹å¹¶è¿”å›ã€‚
4. åœ¨ `Append` æ–¹æ³•çš„å›è°ƒä¸­ï¼Œå¦‚æœ `proc` å¤±è´¥åˆ›å»ºï¼Œåˆ™è¿”å›ä¸€ä¸ªé”™è¯¯ã€‚å¦åˆ™ï¼Œå°† `proc` çš„ `Close()` æ–¹æ³•è¿”å›ï¼Œè¡¨ç¤ºæ•´ä¸ªè¿‡ç¨‹æˆåŠŸå®Œæˆã€‚


```
// Append wraps ProcessFunc into a goprocess, and appends it to the lifecycle
func (lp *lcProcess) Append(f goprocess.ProcessFunc) {
	// Hooks are guaranteed to run in sequence. If a hook fails to start, its
	// OnStop won't be executed.
	var proc goprocess.Process

	lp.LC.Append(fx.Hook{
		OnStart: func(ctx context.Context) error {
			proc = lp.Proc.Go(f)
			return nil
		},
		OnStop: func(ctx context.Context) error {
			if proc == nil { // Theoretically this shouldn't ever happen
				return errors.New("lcProcess: proc was nil")
			}

			return proc.Close() // todo: respect ctx, somehow
		},
	})
}

```

è¿™ä¸¤æ®µä»£ç å®šä¹‰äº† `maybeProvide` å’Œ `maybeInvoke` å‡½æ•°ï¼Œå®ƒä»¬éƒ½æ¥å—ä¸€ä¸ª `opt` å‚æ•°å’Œä¸€ä¸ª `enable` å¸ƒå°”å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ª `fx.Option` ç±»å‹çš„å‡½æ•°ã€‚

`fx.Option` æ˜¯ä¸€ä¸ª Lambda å‡½æ•°ç±»å‹ï¼Œå®ƒæ¥å—ä¸€ä¸ªå‡½æ•°ä½œä¸ºå‚æ•°ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«é€‰é¡¹çš„å¯¹è±¡ï¼Œå¯ä»¥ä½¿ç”¨ `fmap` å’Œ `void` å‡½æ•°æ¥è¿”å›ä¸€ä¸ªé—­åŒ…ã€‚

`func maybeProvide` å’Œ `func maybeInvoke` çš„ä½œç”¨æ˜¯åœ¨å‡½æ•°ç­¾åä¸­å£°æ˜é»˜è®¤å®ç°ï¼Œå¦‚æœ `enable` ä¸º `true`ï¼Œåˆ™è°ƒç”¨ `fx.Provide` å’Œ `fx.Invoke`ï¼Œå¦åˆ™è¿”å›é»˜è®¤å®ç°ï¼Œå³ `fx.Options()`ã€‚


```
func maybeProvide(opt interface{}, enable bool) fx.Option {
	if enable {
		return fx.Provide(opt)
	}
	return fx.Options()
}

// nolint unused
func maybeInvoke(opt interface{}, enable bool) fx.Option {
	if enable {
		return fx.Invoke(opt)
	}
	return fx.Options()
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸ºâ€œbaseProcessâ€çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ªåä¸ºâ€œlifecycleâ€çš„å‚æ•°ï¼Œè¯¥å‚æ•°æ˜¯ä¸€ä¸ªåä¸ºâ€œfx.Lifecycleâ€çš„ç±»å‹ï¼Œè¯¥ç±»å‹è¡¨ç¤ºä¸€ä¸ªç³»ç»Ÿçš„ç”Ÿå‘½å‘¨æœŸã€‚

å‡½æ•°å†…éƒ¨åˆ›å»ºäº†ä¸€ä¸ªåä¸ºâ€œpâ€çš„goprocesså®ä¾‹ï¼Œè¯¥å®ä¾‹ä½¿ç”¨åä¸ºâ€œbackgroundâ€çš„çˆ¶è¿›ç¨‹ï¼Œç„¶åå°†åä¸ºâ€œlifecycleâ€çš„å‚æ•°ä¼ é€’ç»™â€œlifecycle.Appendâ€æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ä¸€ä¸ªåä¸ºâ€œOnStopâ€çš„åŒ¿åå‡½æ•°æ³¨å†Œä¸ºâ€œlifecycleâ€çš„åœæ­¢ä¿¡å·ã€‚

å…·ä½“æ¥è¯´ï¼Œå½“å‡½æ•°åˆ›å»ºçš„è¿›ç¨‹è¢«åœæ­¢æ—¶ï¼Œå°†è°ƒç”¨â€œOnStopâ€ä¿¡å·ï¼Œä¿¡å·çš„å‚æ•°æ˜¯ä¸€ä¸ªåä¸ºâ€œcontextâ€çš„åŒ¿åæ¥å£ï¼Œè¯¥æ¥å£åŒ…å«ä¸€ä¸ªâ€œcloseâ€æ–¹æ³•ï¼Œç”¨äºå…³é—­ä¸å½“å‰è¿›ç¨‹ç›¸å…³çš„èµ„æºï¼Œç„¶åè¿”å›ä¸€ä¸ªâ€œerrorâ€ç±»å‹çš„å€¼ï¼Œè¡¨ç¤ºå…³é—­è¿‡ç¨‹ä¸­å‘ç”Ÿçš„æƒ…å†µã€‚


```
// baseProcess creates a goprocess which is closed when the lifecycle signals it to stop
func baseProcess(lc fx.Lifecycle) goprocess.Process {
	p := goprocess.WithParent(goprocess.Background())
	lc.Append(fx.Hook{
		OnStop: func(_ context.Context) error {
			return p.Close()
		},
	})
	return p
}

```

# `/opt/kubo/core/node/identity.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `PeerID` çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªåä¸º `id` çš„ `peer.ID` å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªå‡½æ•°ï¼Œä½¿å¾—è¯¥å‡½æ•°è°ƒç”¨æ—¶å¯ä»¥è·å¾— `id` çš„å€¼ã€‚

è¯¥å‡½æ•°çš„å®ç°ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š

1. åœ¨å‡½æ•°å®šä¹‰æ—¶ï¼Œé¦–å…ˆå¯¼å…¥äº† `node` å’Œ `github.com/libp2p/go-libp2p/core` åŒ…ï¼Œè¿™ä¸¤ä¸ªåŒ…åˆ†åˆ«ç”¨äºä» Node.js çš„ `package.json` æ–‡ä»¶ä¸­è¯»å– Node ID åœ°å€ä»¥åŠä»è¯¥åŒ…ä¸­å¯¼å…¥ `core/crypto` å’Œ `core/peer` åŒ…ã€‚

2. æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†åä¸º `PeerID` çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ªåä¸º `id` çš„ `peer.ID` å‚æ•°ï¼Œç„¶åè¿”å›ä¸€ä¸ªè¿”å›å€¼ï¼Œè¯¥è¿”å›å€¼ä¸è¾“å…¥å‚æ•° `id` ç›¸åŒã€‚

é€šè¿‡ `PeerID` å‡½æ•°ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°è·å–ä¼ å…¥å‚æ•° `id` çš„å€¼ï¼Œè¿™å¯¹äºåç»­çš„åŒºå—é“¾ç½‘ç»œé€šä¿¡ç­‰æ“ä½œéå¸¸æœ‰ç”¨ã€‚


```
package node

import (
	"fmt"

	"github.com/libp2p/go-libp2p/core/crypto"
	"github.com/libp2p/go-libp2p/core/peer"
)

func PeerID(id peer.ID) func() peer.ID {
	return func() peer.ID {
		return id
	}
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `PrivateKey` çš„å‡½æ•°ï¼Œå®ƒä»é…ç½®ä¸­è¯»å–ç§é’¥å¹¶è¿”å›ä¸€ä¸ª `crypto.PrivKey` ç±»å‹çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥éªŒè¯ä¼ å…¥çš„ `peer.ID` æ˜¯å¦ä¸ç§é’¥åŒ¹é…ã€‚å¦‚æœåŒ¹é…æˆåŠŸï¼Œå‡½æ•°è¿”å›ç§é’¥ï¼›å¦‚æœåŒ¹é…å¤±è´¥ï¼Œå‡½æ•°è¿”å› `nil` å’Œé”™è¯¯ä¿¡æ¯ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™æ®µä»£ç å®ç°äº†ä¸€ä¸ªç§æœ‰å‡½æ•°ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ª `crypto.PrivKey` ç±»å‹çš„å‚æ•°ï¼Œå¹¶å°†å…¶å°è£…ä¸º `func(id peer.ID) (crypto.PrivKey, error)` ç±»å‹çš„å‡½æ•°ã€‚å‡½æ•°é¦–å…ˆå°è¯•ä»é…ç½®ä¸­è¯»å–ç§é’¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª `peer.ID` ç±»å‹çš„å˜é‡ `id2`ã€‚ç„¶åï¼Œå‡½æ•°æ¯”è¾ƒä¼ å…¥çš„ `id` å’Œ `id2` æ˜¯å¦ç›¸ç­‰ã€‚å¦‚æœä¸¤ä¸ª `peer.ID` ä¸ç›¸ç­‰ï¼Œå‡½æ•°è¿”å› `nil` å’Œé”™è¯¯ä¿¡æ¯ã€‚å¦åˆ™ï¼Œå‡½æ•°è¿”å›ç§é’¥å¹¶ `nil`ï¼Œä»¥è¡¨æ˜ä¼ å…¥çš„ `id` æ ¼å¼æ­£ç¡®ã€‚


```
// PrivateKey loads the private key from config
func PrivateKey(sk crypto.PrivKey) func(id peer.ID) (crypto.PrivKey, error) {
	return func(id peer.ID) (crypto.PrivKey, error) {
		id2, err := peer.IDFromPrivateKey(sk)
		if err != nil {
			return nil, err
		}

		if id2 != id {
			return nil, fmt.Errorf("private key in config does not match id: %s != %s", id, id2)
		}
		return sk, nil
	}
}

```

# `/opt/kubo/core/node/ipns.go`

è¯¥ä»£ç æ˜¯ä¸€ä¸ª Node åŒ…ï¼Œå…¶ä¸­åŒ…å«äº†ä¸€äº›ç”¨äºåœ¨ Node.js ä¸­æ“ä½œ IPFS(InterPlanetary File System)çš„å‡½æ•°å’Œç»“æ„ä½“ã€‚IPFS æ˜¯ä¸€ä¸ªå»ä¸­å¿ƒåŒ–çš„ç‚¹å¯¹ç‚¹æ–‡ä»¶å­˜å‚¨ç½‘ç»œï¼Œå¯ä»¥ç”¨æ¥å­˜å‚¨å’Œå…±äº«æ–‡ä»¶å’Œæ•°æ®ã€‚

å…·ä½“æ¥è¯´ï¼Œè¯¥ä»£ç å®ç°äº†ä»¥ä¸‹åŠŸèƒ½ï¼š

1. å¯¼å…¥äº† Node.js ä¸­ä½¿ç”¨çš„ IPFS ç›¸å…³çš„åº“å’Œå‡½æ•°ï¼ŒåŒ…æ‹¬ `ipfs`ã€`util`ã€`record`ã€`crypto`ã€`peerstore`ã€`madns`ã€`namesys`ã€`repo` å’Œ `irouting`ã€‚

2. å®šä¹‰äº†ä¸€äº›ç»“æ„ä½“ï¼ŒåŒ…æ‹¬ `boxo.NamesysItem`ã€`boxo.NamesysItem` å’Œ `ç›’ o.NamesysItem`ã€‚å…¶ä¸­ï¼Œ`boxo.NamesysItem` æ˜¯ `namesys` åº“ä¸­çš„ä¸€ä¸ªç»“æ„ä½“ï¼Œç”¨äºè¡¨ç¤º IPFS ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ƒåŒ…å«äº†ä¸€ä¸ªåç§°å’Œä¸€ä¸ªæŒ‡å‘è¯¥èŠ‚ç‚¹çš„æŒ‡é’ˆã€‚

3. å®ç°äº† `util.Connect` å‡½æ•°ï¼Œç”¨äºè¿æ¥åˆ° IPFS æœåŠ¡å™¨å¹¶åˆ›å»ºä¸€ä¸ª `peerstore` å®ä¾‹ã€‚

4. å®ç°äº† `util. disconnect` å‡½æ•°ï¼Œç”¨äºå…³é—­ä¸ IPFS æœåŠ¡å™¨é€šä¿¡å¹¶åœæ­¢ `peerstore` å®ä¾‹ã€‚

5. å®ç°äº† `boxo.Boxo` ç±»ï¼Œç”¨äºç®¡ç† IPFS ä¸­çš„æ–‡ä»¶å’Œç›®å½•ã€‚è¯¥ç±»å®ç°äº† `boxo.NamesysItem` ç»“æ„ä½“ä¸­çš„ `name` å’Œ `connect` æ–¹æ³•ï¼Œç”¨äºè·å–å’Œè¿æ¥åˆ° IPFS æœåŠ¡å™¨ã€‚

6. å®ç°äº† `boxo.BoxoAttachment` ç±»ï¼Œç”¨äºç®¡ç† IPFS ä¸­çš„æ–‡ä»¶å’Œç›®å½•çš„é™„ä»¶ã€‚è¯¥ç±»å®ç°äº† `boxo.NamesysItem` ç»“æ„ä½“ä¸­çš„ `é™„åŠ ` æ–¹æ³•ï¼Œç”¨äºå°†æ–‡ä»¶æˆ–ç›®å½•é™„åŠ åˆ° IPFS æœåŠ¡å™¨ä¸Šã€‚

7. å®ç°äº† `boxo.BoxoDaemon` ç±»ï¼Œç”¨äºç®¡ç† IPFS æœåŠ¡å™¨ã€‚è¯¥ç±»å®ç°äº† `boxo.NamesysItem` ç»“æ„ä½“ä¸­çš„ `daemon` æ–¹æ³•ï¼Œç”¨äºå¯åŠ¨æˆ–åœæ­¢ IPFS æœåŠ¡å™¨ã€‚

8. å®ç°äº† `namesys.NsRepo` ç±»ï¼Œç”¨äºç®¡ç† IPFS æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶å’Œç›®å½•ã€‚è¯¥ç±»å®ç°äº† `repo.NsRepo` ç±»ä¸­çš„ `filesystem` å’Œ `directory` æ–¹æ³•ï¼Œç”¨äºåœ¨ IPFS æœåŠ¡å™¨ä¸Šè¯»å–å’Œå†™å…¥æ–‡ä»¶ã€‚

9. å®ç°äº† `repo.NsRepo` ç±»ï¼Œç”¨äºç®¡ç† IPFS æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶å’Œç›®å½•ã€‚è¯¥ç±»å®ç°äº† `repo.NsRepo` ç±»ä¸­çš„ `filesystem` å’Œ `directory` æ–¹æ³•ï¼Œç”¨äºåœ¨ IPFS æœåŠ¡å™¨ä¸Šè¯»å–å’Œå†™å…¥æ–‡ä»¶ã€‚

10. å®ç°äº† `irouting.Irp` ç±»ï¼Œç”¨äºç®¡ç† IPFS è·¯ç”±ã€‚è¯¥ç±»å®ç°äº† `irouting.Irp` ç±»ä¸­çš„ `parse` å’Œ `route` æ–¹æ³•ï¼Œç”¨äºè§£æå’Œè·¯ç”± IPFS è·¯ç”±ã€‚


```
package node

import (
	"fmt"
	"time"

	"github.com/ipfs/boxo/ipns"
	util "github.com/ipfs/boxo/util"
	record "github.com/libp2p/go-libp2p-record"
	"github.com/libp2p/go-libp2p/core/crypto"
	"github.com/libp2p/go-libp2p/core/peerstore"
	madns "github.com/multiformats/go-multiaddr-dns"

	"github.com/ipfs/boxo/namesys"
	"github.com/ipfs/boxo/namesys/republisher"
	"github.com/ipfs/kubo/repo"
	irouting "github.com/ipfs/kubo/routing"
)

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º`RecordValidator`çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªåä¸º`peerstore`çš„Peerstoreç±»å‹çš„å‚æ•°ã€‚`RecordValidator`çš„ä½œç”¨æ˜¯éªŒè¯è·¯ç”±è®°å½•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¿”å›ä¸€ä¸ª`namesys.Validator`ç±»å‹çš„ç»“æœã€‚

å…·ä½“æ¥è¯´ï¼Œå‡½æ•°ä¸­é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªåä¸º`DefaultIpnsCacheSize`çš„å¸¸é‡ï¼Œå…¶å€¼ä¸º128ã€‚ç„¶åï¼Œå‡½æ•°å®šä¹‰äº†ä¸€ä¸ªåä¸º`Namesys`çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªåä¸º`cacheSize`çš„æ•´æ•°å‚æ•°ã€‚è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯åœ¨åˆ›å»ºä¸€ä¸ªæ–°çš„Namesyså®ä¾‹æ—¶å¯ä»¥è®¾ç½®ä¸€ä¸ªç¼“å­˜å¤§å°ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡½æ•°å†…éƒ¨å®šä¹‰äº†ä¸€ç³»åˆ—çš„é€‰é¡¹ï¼ŒåŒ…æ‹¬ä½¿ç”¨Datastoreã€DNSResolverã€ä»¥åŠä½¿ç”¨ç¼“å­˜ç­‰ã€‚æœ€åï¼Œå‡½æ•°è°ƒç”¨äº†ä¸€ä¸ªåä¸º`WithCache`çš„é€‰é¡¹ï¼Œè¯¥é€‰é¡¹å¯ä»¥å°†ç¼“å­˜å¤§å°å‚æ•°åŒ–ã€‚

é€šè¿‡è°ƒç”¨`Namesys`å‡½æ•°å¹¶ä¼ å…¥æ‰€éœ€çš„å‚æ•°ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„Namesyså®ä¾‹ï¼Œç”¨äºè·¯ç”±è®°å½•çš„éªŒè¯ã€‚


```
const DefaultIpnsCacheSize = 128

// RecordValidator provides namesys compatible routing record validator
func RecordValidator(ps peerstore.Peerstore) record.Validator {
	return record.NamespacedValidator{
		"pk":   record.PublicKeyValidator{},
		"ipns": ipns.Validator{KeyBook: ps},
	}
}

// Namesys creates new name system
func Namesys(cacheSize int) func(rt irouting.ProvideManyRouter, rslv *madns.Resolver, repo repo.Repo) (namesys.NameSystem, error) {
	return func(rt irouting.ProvideManyRouter, rslv *madns.Resolver, repo repo.Repo) (namesys.NameSystem, error) {
		opts := []namesys.Option{
			namesys.WithDatastore(repo.Datastore()),
			namesys.WithDNSResolver(rslv),
		}

		if cacheSize > 0 {
			opts = append(opts, namesys.WithCache(cacheSize))
		}

		return namesys.NewNameSystem(rt, opts...)
	}
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º`IpnsRepublisher`çš„å‡½æ•°ï¼Œå®ƒå®ç°äº†IPNSï¼ˆInter-Platform Security Serviceï¼‰çš„`republisher`æœåŠ¡ã€‚`republisher`æœåŠ¡çš„åŠŸèƒ½æ˜¯å®šæœŸå°†ç‰¹å®šç›®å½•ä¸‹çš„æ–‡ä»¶å’Œå¯¹åº”çš„ç”¨æˆ·ä¿¡æ¯åŒæ­¥åˆ°IPNSçš„å­˜å‚¨ç³»ç»Ÿä¸­ã€‚

ä»¥ä¸‹æ˜¯`IpnsRepublisher`å‡½æ•°çš„åŠŸèƒ½è§£é‡Šï¼š

1. å‡½æ•°æ¥å—å››ä¸ªå‚æ•°ï¼š`repubPeriod`è¡¨ç¤ºå®šæ—¶å™¨è®¾ç½®çš„å®šæœŸï¼Œ`recordLifetime`è¡¨ç¤ºåŒæ­¥è¿‡ç¨‹ä¸­æ–‡ä»¶å’Œç”¨æˆ·çš„å¯¿å‘½ã€‚

2. `repubPeriod`çš„åˆ¤æ–­ï¼š

  - å¦‚æœ`repubPeriod`çš„å€¼åœ¨`time.Minute`å’Œ`time.Hour`ä¹‹é—´ï¼Œå‡½æ•°å°†è¿”å›ä¸€ä¸ªé”™è¯¯ï¼Œè¯´æ˜è®¾ç½®çš„å®šæ—¶å™¨è¶…å‡ºäº†å…è®¸çš„æœ€çŸ­å’Œæœ€é•¿æ—¶é—´ã€‚

  - å¦‚æœ`repubPeriod`çš„å€¼ä¸åœ¨`time.Minute`å’Œ`time.Hour`ä¹‹é—´ï¼Œå‡½æ•°å°†ä»é¢„å®šä¹‰çš„é”™è¯¯æ¶ˆæ¯ä¸­é€‰æ‹©ä¸€ä¸ªé€‚å½“çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶è¿”å›è¯¥é”™è¯¯ä¿¡æ¯ã€‚

3. `recordLifetime`çš„åˆ¤æ–­ï¼š

  - å¦‚æœ`recordLifetime`çš„å€¼ä¸º0ï¼Œå‡½æ•°å°†ä»é¢„å®šä¹‰çš„é”™è¯¯æ¶ˆæ¯ä¸­é€‰æ‹©ä¸€ä¸ªé€‚å½“çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶è¿”å›è¯¥é”™è¯¯ä¿¡æ¯ã€‚

  - å¦‚æœ`recordLifetime`çš„å€¼ä¸ä¸º0ï¼Œå‡½æ•°å°†ä»é¢„å®šä¹‰çš„é”™è¯¯æ¶ˆæ¯ä¸­é€‰æ‹©ä¸€ä¸ªé€‚å½“çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶æ›´æ–°åŒæ­¥è¿‡ç¨‹ä¸­çš„æ–‡ä»¶å’Œç”¨æˆ·çš„å¯¿å‘½ã€‚

4. `IpnsRepublisher`å‡½æ•°çš„ä½œç”¨ï¼š

  - åˆ›å»ºä¸€ä¸ªåä¸º`repub`çš„`republisher.Repub`å®ä¾‹ã€‚

  - ä½¿ç”¨`republisher.NewRepublisher`æ–¹æ³•è®¾ç½®å®šæ—¶å™¨ï¼Œè®¾ç½®å®šæœŸä¸º`repubPeriod`ï¼Œè®¾ç½®åŒæ­¥è¿‡ç¨‹ä¸­æ–‡ä»¶çš„å¯¿å‘½ä¸º`recordLifetime`ã€‚

  - è®¾ç½®`repub.Run`ä¸º`lc.Append`çš„å›è°ƒå‡½æ•°ï¼Œä»¥ä¾¿åœ¨åŒæ­¥è¿‡ç¨‹ä¸­å°†ä¸‹è½½çš„æ–‡ä»¶å’Œç”¨æˆ·ä¿¡æ¯å†™å…¥ä¸‹è½½çš„æ–‡ä»¶ä¸­ã€‚

  - è¿”å›`nil`è¡¨ç¤º`IpnsRepublisher`å‡½æ•°æ²¡æœ‰è¿”å›ä»»ä½•é”™è¯¯ã€‚


```
// IpnsRepublisher runs new IPNS republisher service
func IpnsRepublisher(repubPeriod time.Duration, recordLifetime time.Duration) func(lcProcess, namesys.NameSystem, repo.Repo, crypto.PrivKey) error {
	return func(lc lcProcess, namesys namesys.NameSystem, repo repo.Repo, privKey crypto.PrivKey) error {
		repub := republisher.NewRepublisher(namesys, repo.Datastore(), privKey, repo.Keystore())

		if repubPeriod != 0 {
			if !util.Debug && (repubPeriod < time.Minute || repubPeriod > (time.Hour*24)) {
				return fmt.Errorf("config setting IPNS.RepublishPeriod is not between 1min and 1day: %s", repubPeriod)
			}

			repub.Interval = repubPeriod
		}

		if recordLifetime != 0 {
			repub.RecordLifetime = recordLifetime
		}

		lc.Append(repub.Run)
		return nil
	}
}

```

# `/opt/kubo/core/node/peering.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `Peering` çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼š`lc` å’Œ `host`ã€‚`lc` æ˜¯ä¸€ä¸ª `fx.Lifecycle` ç±»å‹çš„å‡½æ•°ï¼Œå®ƒè¡¨ç¤ºæ•´ä¸ªåº”ç”¨ç¨‹åºçš„ç”Ÿå‘½å‘¨æœŸï¼Œ`host` æ˜¯ä¸€ä¸ª `host.Host` ç±»å‹çš„å‡½æ•°ï¼Œå®ƒè¡¨ç¤ºè¦è¿æ¥åˆ°çš„ä¸»æœºã€‚

è¯¥å‡½æ•°é¦–å…ˆå¼•å…¥äº† `node` åŒ…ã€`github.com/ipfs/boxo/peering` åŒ…ã€`github.com/libp2p/go-libp2p/core/host` åŒ…å’Œ `github.com/libp2p/go-libp2p/core/peer` åŒ…ã€‚ç„¶åï¼Œè¯¥å‡½æ•°å®šä¹‰äº†ä¸€ä¸ªåä¸º `PeeringService` çš„ç±»å‹ï¼Œè¯¥ç±»å‹è¡¨ç¤ºåˆ›å»ºä¸€ä¸ª `peering.PeeringService` å®ä¾‹å¹¶å°†å…¶è¿æ¥åˆ°æŒ‡å®šçš„ä¸»æœºä¸Šã€‚

æ¥ä¸‹æ¥ï¼Œè¯¥å‡½æ•°å®ç°äº†ä¸¤ä¸ªé’©å­ï¼š`OnStart` å’Œ `OnStop`ã€‚`OnStart` é’©å­å°†åœ¨ç»„ä»¶å¯åŠ¨æ—¶æ‰§è¡Œï¼Œå®ƒè¿”å›ä¸€ä¸ª `nil`ï¼Œç¡®ä¿ `PeeringService` å¼€å§‹æ—¶ä¸ä¼šäº§ç”Ÿä»»ä½•é”™è¯¯ã€‚`OnStop` é’©å­å°†åœ¨ç»„ä»¶åœæ­¢æ—¶æ‰§è¡Œï¼Œå®ƒæ¸…é™¤ `PeeringService` å¹¶åœæ­¢å…¶ä¸ä¸»æœºçš„è¿æ¥ï¼Œç¡®ä¿åœ¨ç»„ä»¶å…³é—­æ—¶åœæ­¢ä»»ä½•å¯èƒ½äº§ç”Ÿçš„æ“ä½œã€‚


```
package node

import (
	"context"

	"github.com/ipfs/boxo/peering"
	"github.com/libp2p/go-libp2p/core/host"
	"github.com/libp2p/go-libp2p/core/peer"
	"go.uber.org/fx"
)

// Peering constructs the peering service and hooks it into fx's lifetime
// management system.
func Peering(lc fx.Lifecycle, host host.Host) *peering.PeeringService {
	ps := peering.NewPeeringService(host)
	lc.Append(fx.Hook{
		OnStart: func(context.Context) error {
			return ps.Start()
		},
		OnStop: func(context.Context) error {
			ps.Stop()
			return nil
		},
	})
	return ps
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º`PeerWith`çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªæˆ–å¤šä¸ª`peer.AddrInfo`ç±»å‹çš„å‚æ•°ï¼Œç„¶åä½¿ç”¨è¿™äº›å‚æ•°é…ç½®å¯¹æŒ‡å®š`peer.PeeringService`çš„é…ç½®ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š

1. å®šä¹‰äº†ä¸€ä¸ª`PeerWith`å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªæˆ–å¤šä¸ª`peer.AddrInfo`ç±»å‹çš„å‚æ•°ã€‚
2. é€šè¿‡éå†`peers`åˆ‡ç‰‡ï¼Œå°†æ¥æ”¶åˆ°çš„`peer.AddrInfo`ç±»å‹æ·»åŠ åˆ°`peering.PeeringService`å®ä¾‹ä¸­ã€‚
3. è¿”å›å·²ç»é…ç½®å¥½çš„`PeerWith`å‡½æ•°ã€‚

è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯å®šä¹‰äº†ä¸€ä¸ª`PeerWith`å‡½æ•°ï¼Œç”¨äºé…ç½®ä¸€ä¸ª`peer.PeeringService`ä¸æŒ‡å®šçš„`peer.AddrInfo`ç±»å‹çš„æœåŠ¡å™¨è¿›è¡Œå¯¹ç­‰è¿æ¥ã€‚


```
// PeerWith configures the peering service to peer with the specified peers.
func PeerWith(peers ...peer.AddrInfo) fx.Option {
	return fx.Invoke(func(ps *peering.PeeringService) {
		for _, ai := range peers {
			ps.AddPeer(ai)
		}
	})
}

```

# `/opt/kubo/core/node/provider.go`

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ª Node åŒ…ï¼Œå®ƒå®šä¹‰äº†ä¸€ç³»åˆ—ç”¨äºä¸ IPFS å­˜å‚¨æ¡¶è¿›è¡Œäº¤äº’çš„å‡½æ•°å’Œå˜é‡ã€‚

å…·ä½“æ¥è¯´ï¼Œè¿™ä¸ªåŒ…å®šä¹‰äº†ä¸€ä¸ªåä¸º "node" çš„å‡½æ•°æ¥æ”¶è€…ï¼Œå®ƒå°†æ‰€æœ‰ä¸ IPFS å­˜å‚¨æ¡¶ç›¸å…³çš„æ“ä½œå°è£…åœ¨è¿™ä¸ªå‡½æ•°ä¸­ã€‚è¿™ä¸ªå‡½æ•°æ¥æ”¶è€…ä½¿ç”¨äº†ä¸€ä¸ªåä¸º "fmt" çš„å‡½æ•°æ¥æ ¼å¼åŒ–è¾“å…¥å’Œè¾“å‡ºæ•°æ®ã€‚

ä¸‹é¢æ˜¯ç”¨äºè§£é‡Šè¿™ä¸ªå‡½æ•°æ¥æ”¶è€…çš„ä»£ç ï¼š


package node

import (
	"context"
	"fmt"
	"time"

	"github.com/ipfs/boxo/blockstore"
	"github.com/ipfs/boxo/fetcher"
	pin "github.com/ipfs/boxo/pinning/pinner"
	provider "github.com/ipfs/boxo/provider"
	"github.com/ipfs/kubo/repo"
	irouting "github.com/ipfs/kubo/routing"
	"go.uber.org/fx"
)


è¿™ä¸ªå‡½æ•°æ¥æ”¶è€…ä»ä¸Šä¸‹æ–‡ä¸­è·å–ä¸€ä¸ªå—å­˜å‚¨å™¨ä¸Šä¸‹æ–‡ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥è·å–å’Œè®¾ç½®å—å­˜å‚¨å™¨ã€‚å®ƒè¿˜ä½¿ç”¨ä¸€ä¸ªåä¸º "fetcher" çš„å‡½æ•°æ¥è·å–æ¥è‡ª IPFS å­˜å‚¨æ¡¶çš„å†…å®¹ï¼Œå¹¶ä½¿ç”¨ "pin" å‡½æ•°æ¥å°†å†…å®¹ä¸æœ¬åœ° PIN å­˜å‚¨å™¨è¿›è¡Œå…³è”ã€‚

æ­¤å¤–ï¼Œå®ƒè¿˜å®šä¹‰äº†ä¸€ä¸ª "provider" å‡½æ•°ï¼Œç”¨äºè®¾ç½®ä¸ IPFS å­˜å‚¨æ¡¶çš„è¿æ¥ä¸Šä¸‹æ–‡ï¼Œä»¥åŠä¸€ä¸ª "repo" å‡½æ•°ï¼Œç”¨äºä¸å—å­˜å‚¨å™¨è¿›è¡Œäº¤äº’ã€‚

æœ€åï¼Œå®ƒè¿˜å®šä¹‰äº†ä¸€ä¸ª "irouting" å‡½æ•°ï¼Œç”¨äºè®¾ç½®è·¯ç”±å’Œè·¯ç”±è§„åˆ™ï¼Œä»¥åŠä¸€ä¸ª "node" å‡½æ•°ï¼Œç”¨äºå°†æ‰€æœ‰ä¸ IPFS å­˜å‚¨æ¡¶ç›¸å…³çš„æ“ä½œå°è£…æˆä¸€ä¸ªå‡½æ•°ã€‚


```
package node

import (
	"context"
	"fmt"
	"time"

	"github.com/ipfs/boxo/blockstore"
	"github.com/ipfs/boxo/fetcher"
	pin "github.com/ipfs/boxo/pinning/pinner"
	provider "github.com/ipfs/boxo/provider"
	"github.com/ipfs/kubo/repo"
	irouting "github.com/ipfs/kubo/routing"
	"go.uber.org/fx"
)

```

It looks like the CIDs we have to provide are already fetched from the blockstore.

To answer your original question, the number of blocks that can be fetched from the blockstore in a 10-teb blockstore with 128KiB blocks per 1024 KiB block is approximately 61 blocks.

This is because each 128KiB block represents approximately 5.76 MB of data. And 10-teb blockstore is 10 pB.

So, it would be 10/5.76=1719200 block.

However, it is important to note that this is a rough estimate and the actual number of blocks that can be fetched may vary depending on the specific implementation and the properties of the blockstore.


```
func ProviderSys(reprovideInterval time.Duration, acceleratedDHTClient bool) fx.Option {
	const magicThroughputReportCount = 128
	return fx.Provide(func(lc fx.Lifecycle, cr irouting.ProvideManyRouter, keyProvider provider.KeyChanFunc, repo repo.Repo, bs blockstore.Blockstore) (provider.System, error) {
		opts := []provider.Option{
			provider.Online(cr),
			provider.ReproviderInterval(reprovideInterval),
			provider.KeyProvider(keyProvider),
		}
		if !acceleratedDHTClient {
			// The estimation kinda suck if you are running with accelerated DHT client,
			// given this message is just trying to push people to use the acceleratedDHTClient
			// let's not report on through if it's in use
			opts = append(opts,
				provider.ThroughputReport(func(reprovide bool, complete bool, keysProvided uint, duration time.Duration) bool {
					avgProvideSpeed := duration / time.Duration(keysProvided)
					count := uint64(keysProvided)

					if !reprovide || !complete {
						// We don't know how many CIDs we have to provide, try to fetch it from the blockstore.
						// But don't try for too long as this might be very expensive if you have a huge datastore.
						ctx, cancel := context.WithTimeout(context.Background(), time.Minute*5)
						defer cancel()

						// FIXME: I want a running counter of blocks so size of blockstore can be an O(1) lookup.
						ch, err := bs.AllKeysChan(ctx)
						if err != nil {
							logger.Errorf("fetching AllKeysChain in provider ThroughputReport: %v", err)
							return false
						}
						count = 0
					countLoop:
						for {
							select {
							case _, ok := <-ch:
								if !ok {
									break countLoop
								}
								count++
							case <-ctx.Done():
								// really big blockstore mode

								// how many blocks would be in a 10TiB blockstore with 128KiB blocks.
								const probableBigBlockstore = (10 * 1024 * 1024 * 1024 * 1024) / (128 * 1024)
								// How long per block that lasts us.
								expectedProvideSpeed := reprovideInterval / probableBigBlockstore
								if avgProvideSpeed > expectedProvideSpeed {
									logger.Errorf(`
```

è¿™æ®µä»£ç çœ‹èµ·æ¥æ˜¯ç”¨äºæŠ¥å‘ŠDHT(åˆ†å¸ƒå¼å“ˆå¸Œç½‘ç»œ) ä¸­çš„é”®å€¼å¯¹(key-value pair) æäº¤é€Ÿç‡(average rate) ä»¥åŠä¼°è®¡çš„å—å­˜å‚¨å™¨å¤§å°(block store size) æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚å®ƒæä¾›äº†ä¸€äº›é”™è¯¯æ¶ˆæ¯ï¼Œå¹¶å»ºè®®é‡‡å–è¡ŒåŠ¨ä»¥æé«˜ç³»ç»Ÿæ€§èƒ½ã€‚

é¦–å…ˆï¼Œå®ƒå‘ŠçŸ¥æ‚¨ï¼Œç”±äºæŸäº›åŸå› ï¼ŒDHTçš„é”®å€¼å¯¹æäº¤é€Ÿç‡å¯èƒ½æ— æ³•è·Ÿä¸Šï¼Œå¯¼è‡´æ‚¨çš„å†…å®¹åœ¨ç½‘ç»œä¸Šå¯èƒ½æ— æ³•å®Œå…¨è®¿é—®ã€‚å®ƒå»ºè®®æ‚¨æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦èƒ½å¤Ÿæ”¯æŒDHTçš„reprovideåŠŸèƒ½ï¼ŒreprovideåŠŸèƒ½å°†å°è¯•é‡æ–°ä¸DHTæœåŠ¡å™¨é€šä¿¡å¹¶é‡æ–°è·å–æ•°æ®ã€‚

å¦‚æœæ‚¨çš„ç³»ç»Ÿæ— æ³•æ”¯æŒreprovideåŠŸèƒ½ï¼Œåˆ™å®ƒå»ºè®®æ‚¨ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š 


aws dht-repo-public-client key-value-pair-submit- rates=(avg_rate_per_key || 0) blocks=(max_blocks_to_fetch || 0) num_attempts=(5 || 0) interval=(60 || 0) output_file=/dev/null


è¿™ä¸ªå‘½ä»¤å°†å°è¯•åœ¨æŒ‡å®šæ—¶é—´é—´éš”å†…(å¹³å‡æ¯ key 0.1) å°è¯•å‘DHTæœåŠ¡å™¨æäº¤æŒ‡å®šæ•°é‡çš„é”®å€¼å¯¹ï¼Œå¹¶è¾“å‡ºåˆ°æ§åˆ¶å°ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚

æ­¤å¤–ï¼Œå®ƒè¿˜å‘ŠçŸ¥æ‚¨ï¼Œå¦‚æœæ‚¨çš„ç³»ç»Ÿåœ¨å°è¯•ä½¿ç”¨DHTçš„reprovideåŠŸèƒ½æ—¶é‡åˆ°å›°éš¾ï¼Œåˆ™å¯èƒ½æ˜¯ç”±äºæ‚¨çš„ç³»ç»Ÿåœ¨å¤„ç†å“ˆå¸Œç½‘ç»œè¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå»ºè®®æ‚¨å°è¯•å¯ç”¨åŠ é€Ÿçš„DHTä»¥æé«˜ç³»ç»Ÿæ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæŒ‡å‘GitHubä»“åº“çš„é“¾æ¥ï¼Œä»¥è·å–æœ‰å…³å¦‚ä½•å¯ç”¨åŠ é€ŸDHTçš„æ›´å¤šä¿¡æ¯ã€‚


```
ğŸ””ğŸ””ğŸ”” YOU MAY BE FALLING BEHIND DHT REPROVIDES! ğŸ””ğŸ””ğŸ””

âš ï¸ Your system might be struggling to keep up with DHT reprovides!
This means your content could partially or completely inaccessible on the network.
We observed that you recently provided %d keys at an average rate of %v per key.

ğŸ•‘ An attempt to estimate your blockstore size timed out after 5 minutes,
implying your blockstore might be exceedingly large. Assuming a considerable
size of 10TiB, it would take %v to provide the complete set.

â° The total provide time needs to stay under your reprovide interval (%v) to prevent falling behind!

ğŸ’¡ Consider enabling the Accelerated DHT to enhance your system performance. See:
https://github.com/ipfs/kubo/blob/master/docs/config.md#routingaccelerateddhtclient`,
										keysProvided, avgProvideSpeed, avgProvideSpeed*probableBigBlockstore, reprovideInterval)
									return false
								}
							}
						}
					}

					// How long per block that lasts us.
					expectedProvideSpeed := reprovideInterval / time.Duration(count)
					if avgProvideSpeed > expectedProvideSpeed {
						logger.Errorf(`
```

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ª Go è¯­è¨€ç¼–å†™çš„åº“å‡½æ•°ï¼Œä¸»è¦ä½œç”¨æ˜¯ä½¿ç”¨ DHT (Distributed Hash Table) è¿›è¡Œæ•°æ®å¹¶è¡Œå¤åˆ¶ã€‚å‡½æ•°ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªéå¸¸é‡å­—æ®µï¼Œä¸€ä¸ªæ˜¯ `keysProvided`ï¼Œå¦ä¸€ä¸ªæ˜¯ `count`ã€‚

å‡½æ•°é¦–å…ˆæ£€æŸ¥å½“å‰ CID (Count of Instances) è®¡æ•°ï¼Œå¦‚æœè®¡æ•°è¶…è¿‡äº† `reprovideInterval`ï¼Œå°±è¡¨ç¤ºå½“å‰æ­£å¤„äº DHT å¤åˆ¶å¤±è´¥çš„çŠ¶æ€ã€‚ç„¶åä¼šæ˜¾ç¤ºä¸€ä¸ªè­¦å‘Šä¿¡æ¯ï¼Œå¹¶è¿”å›ä¸€ä¸ªéç©ºå€¼ã€‚

å¦‚æœæˆåŠŸå¤åˆ¶æ•°æ®ï¼Œå‡½æ•°ä¼šä½¿ç”¨æä¾›çš„ `opts...` æ¥è®¾ç½® `repo` å’Œ `provider` å¯¹è±¡ã€‚å¦‚æœè®¾ç½®é”™è¯¯æˆ–è€…åœ¨å°è¯•è°ƒç”¨ä¹‹å‰å‘ç”Ÿé”™è¯¯ï¼Œå‡½æ•°å°†è¿”å›ä¸€ä¸ªéç©ºå€¼ã€‚

æœ€åï¼Œå‡½æ•°ä¼šä½¿ç”¨æä¾›çš„ `sys` å­—æ®µæ¥å…³é—­ä¹‹å‰å»ºç«‹çš„ç³»ç»Ÿå®ä¾‹ï¼Œå¹¶è¿”å›å®ƒã€‚


```
ğŸ””ğŸ””ğŸ”” YOU ARE FALLING BEHIND DHT REPROVIDES! ğŸ””ğŸ””ğŸ””

âš ï¸ Your system is struggling to keep up with DHT reprovides!
This means your content could partially or completely inaccessible on the network.
We observed that you recently provided %d keys at an average rate of %v per key.

ğŸ’¾ Your total CID count is ~%d which would total at %v reprovide process.

â° The total provide time needs to stay under your reprovide interval (%v) to prevent falling behind!

ğŸ’¡ Consider enabling the Accelerated DHT to enhance your reprovide throughput. See:
https://github.com/ipfs/kubo/blob/master/docs/config.md#routingaccelerateddhtclient`,
							keysProvided, avgProvideSpeed, count, avgProvideSpeed*time.Duration(count), reprovideInterval)
					}
					return false
				}, magicThroughputReportCount))
		}
		sys, err := provider.New(repo.Datastore(), opts...)
		if err != nil {
			return nil, err
		}

		lc.Append(fx.Hook{
			OnStop: func(ctx context.Context) error {
				return sys.Close()
			},
		})

		return sys, nil
	})
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `OnlineProviders` çš„å‡½æ•°ï¼Œç”¨äºåœ¨çº¿æä¾›æä¾›å•†è·¯ç”±è®°å½•ã€‚

å‡½æ•°æ¥å—å››ä¸ªå‚æ•°ï¼Œåˆ†åˆ«ä¸º `useStrategicProviding`ã€`reprovideStrategy`ã€`reprovideInterval` å’Œ `acceleratedDHTClient`ã€‚å‡½æ•°å…ˆåˆ¤æ–­ `useStrategicProviding` çš„å€¼æ˜¯å¦ä¸º `true`ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™æ‰§è¡Œå‡½æ•°å†…éƒ¨çš„ä¸€ä¸ªåä¸º `OfflineProviders` çš„å‡½æ•°ï¼Œå¦åˆ™ä¼šè°ƒç”¨å¦ä¸€ä¸ªåä¸º `OnlineProviders` çš„å‡½æ•°ã€‚

å‡½æ•°å†…éƒ¨æ ¹æ® `reprovideStrategy` çš„å€¼æ¥é€‰æ‹©ä½¿ç”¨å“ªç§æä¾›è€…ã€‚`reprovideStrategy` çš„å€¼å¯ä»¥åˆ†ä¸ºä¸‰ç§ï¼Œåˆ†åˆ«ä¸º `"all"`ã€`" roots"` å’Œ `"pinned"`ã€‚å¦‚æœ `reprovideStrategy` çš„å€¼ä¸º `"all"`ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æä¾›è€…ï¼Œå¦‚æœå€¼ä¸º `" roots"`ï¼Œåˆ™ä½¿ç”¨æ ¹æä¾›è€…ï¼Œå¦‚æœå€¼ä¸º `"pinned"` æˆ–è€… `"pinned"` åŠ ä¸Š `"interval"` å‚æ•°ï¼Œåˆ™ä½¿ç”¨å»¶è¿Ÿäº¤äº’çš„æä¾›è€…ã€‚å¦‚æœ `repprovideStrategy` çš„å€¼ä¸æ­£ç¡®ï¼Œå‡½æ•°ä¼šè¿”å›é”™è¯¯å¹¶è¾“å‡º `fmt.Errorf`ã€‚

å‡½æ•°è¿”å›ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå‚æ•°çš„ `fx.Option` ç±»å‹çš„é€‰é¡¹ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ `keyProvider` é€‰é¡¹ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯ `ProviderSys` é€‰é¡¹ï¼Œå…¶ä¸­åŒ…æ‹¬ `reprovideInterval` å’Œ `acceleratedDHTClient` å‚æ•°ã€‚


```
// ONLINE/OFFLINE

// OnlineProviders groups units managing provider routing records online
func OnlineProviders(useStrategicProviding bool, reprovideStrategy string, reprovideInterval time.Duration, acceleratedDHTClient bool) fx.Option {
	if useStrategicProviding {
		return OfflineProviders()
	}

	var keyProvider fx.Option
	switch reprovideStrategy {
	case "all", "":
		keyProvider = fx.Provide(provider.NewBlockstoreProvider)
	case "roots":
		keyProvider = fx.Provide(pinnedProviderStrategy(true))
	case "pinned":
		keyProvider = fx.Provide(pinnedProviderStrategy(false))
	default:
		return fx.Error(fmt.Errorf("unknown reprovider strategy %q", reprovideStrategy))
	}

	return fx.Options(
		keyProvider,
		ProviderSys(reprovideInterval, acceleratedDHTClient),
	)
}

```

è¿™æ®µä»£ç å®šä¹‰äº†ä¸¤ä¸ªå‡½æ•°ï¼Œå®ƒä»¬éƒ½æ¥å—ä¸€ä¸ªåä¸º"offlineProviderStrategy"çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º"pinnedProviderStrategy"çš„æ¥å£ç±»å‹ã€‚

ç¬¬ä¸€ä¸ªå‡½æ•°åä¸º"OfflineProviders"ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªåä¸º"offlineProvider"çš„é€‰é¡¹ï¼Œå®ƒä½¿ç”¨ä¸€ä¸ªåä¸º"NoopProvider"çš„å‡½æ•°ä½œä¸º providerã€‚è¿™ä¸ªé€‰é¡¹çš„ä½œç”¨æ˜¯ returnã€‚

ç¬¬äºŒä¸ªå‡½æ•°åä¸º"pinnedProviderStrategy"ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªåä¸º"onlyRoots"çš„å¸ƒå°”å€¼ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º"pinnedProvider"çš„æ¥å£ç±»å‹ã€‚å®ƒå®šä¹‰äº†ä¸€ä¸ªåä¸º"input"çš„ç»“æ„ä½“ç±»å‹ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªåä¸º"fx.In"ç±»å‹çš„ "input" å­—æ®µã€‚å®ƒè¿˜å®šä¹‰äº†ä¸€ä¸ªåä¸º"Pinner"ç±»å‹çš„ "Pinner" å­—æ®µå’Œä¸€ä¸ªåä¸º "IPLDFetcher" çš„ "fetcher.Factory" å­—æ®µï¼Œå…¶ä¸­ "name" å‚æ•°ä¸º "ipldFetcher"ã€‚å®ƒè¿”å›ä¸€ä¸ªåä¸º "provider.NewPinnedProvider" çš„å‡½æ•°ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªåä¸º "onlyRoots" çš„å¸ƒå°”å€¼ï¼Œä¼ å…¥ä¸€ä¸ª "Pinner" å’Œä¸€ä¸ª "IPLDFetcher" ç±»å‹çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "provider.KeyChanFunc" çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°æ¥æ”¶ä¸€ä¸ª "input" ç±»å‹çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "provider.NewProvider" çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°ä½¿ç”¨ "Pinner" å’Œ "IPLDFetcher" å‚æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„ providerã€‚

æ€»ç»“ä¸€ä¸‹ï¼Œè¿™æ®µä»£ç å®šä¹‰äº†ä¸¤ä¸ªå‡½æ•°ï¼Œå®ƒä»¬éƒ½æ¥å—ä¸€ä¸ªåä¸º "offlineProviderStrategy" çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "pinnedProviderStrategy" çš„æ¥å£ç±»å‹ã€‚ç¬¬ä¸€ä¸ªå‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªåä¸º "offlineProvider" çš„é€‰é¡¹ï¼Œå®ƒä½¿ç”¨ä¸€ä¸ªåä¸º "NoopProvider" çš„å‡½æ•°ä½œä¸º providerã€‚ç¬¬äºŒä¸ªå‡½æ•°å®šä¹‰äº†ä¸€ä¸ªåä¸º "pinnedProviderStrategy" çš„å‡½æ•°ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªåä¸º "onlyRoots" çš„å¸ƒå°”å€¼ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "pinnedProvider" çš„æ¥å£ç±»å‹ã€‚å®ƒå®šä¹‰äº†ä¸€ä¸ªåä¸º "input" çš„ç»“æ„ä½“ç±»å‹ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªåä¸º "fx.In" çš„ "input" å­—æ®µã€‚å®ƒè¿”å›ä¸€ä¸ªåä¸º "provider.NewPinnedProvider" çš„å‡½æ•°ï¼Œå®ƒæ¥æ”¶ä¸€ä¸ªåä¸º "onlyRoots" çš„å¸ƒå°”å€¼ï¼Œä¼ å…¥ä¸€ä¸ª "Pinner" å’Œä¸€ä¸ª "IPLDFetcher" ç±»å‹çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "provider.KeyChanFunc" çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°æ¥æ”¶ä¸€ä¸ª "input" ç±»å‹çš„å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåä¸º "provider.NewProvider" çš„å‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°ä½¿ç”¨ "Pinner" å’Œ "IPLDFetcher" å‚æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„ providerã€‚


```
// OfflineProviders groups units managing provider routing records offline
func OfflineProviders() fx.Option {
	return fx.Provide(provider.NewNoopProvider)
}

func pinnedProviderStrategy(onlyRoots bool) interface{} {
	type input struct {
		fx.In
		Pinner      pin.Pinner
		IPLDFetcher fetcher.Factory `name:"ipldFetcher"`
	}
	return func(in input) provider.KeyChanFunc {
		return provider.NewPinnedProvider(onlyRoots, in.Pinner, in.IPLDFetcher)
	}
}

```

# `/opt/kubo/core/node/storage.go`

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ª Node.js  packageï¼Œå®ƒå®ç°äº†åŸºäº IPFSï¼ˆInterPlanetary File Systemï¼‰çš„ BlockStore å’Œ Repo æœåŠ¡ã€‚ä»¥ä¸‹æ˜¯å®ƒçš„ä¸»è¦åŠŸèƒ½å’Œä½œç”¨ï¼š

1. å¼•å…¥ç›¸åº”çš„åº“å’Œé…ç½®ï¼šé€šè¿‡å¯¼å…¥ "node" åŒ…ä»¥åŠ "github.com/ipfs/boxo/blockstore"ã€"github.com/ipfs/go-datastore"ã€"github.com/ipfs/kubo/config"ã€"github.com/ipfs/kubo/repo" å’Œ "github.com/ipfs/kubo/thirdparty/verifbs" ç­‰åº“ï¼Œå®ç°äº†å¯¹ IPFS ç›¸å…³æœåŠ¡çš„è®¿é—®ã€‚

2. é…ç½® BlockStoreï¼šé€šè¿‡è°ƒç”¨ BlockStore ç±»ä¸­çš„ `repo.SetConfig` æ–¹æ³•ï¼Œè®¾ç½® BlockStore çš„é…ç½®ã€‚è¿™ä¸ªé…ç½®å¯èƒ½åŒ…æ‹¬ä¸€äº›é€‰é¡¹ï¼Œå¦‚ "manifest_baseURI"ï¼Œç”¨äºæŒ‡å®šåˆ†ç‰‡èŠ‚ç‚¹åœ¨ç½‘ç»œä¸­çš„ä½ç½®ã€‚

3. é…ç½® Repoï¼šé€šè¿‡è°ƒç”¨ Repo ç±»ä¸­çš„ `SetConfig` æ–¹æ³•ï¼Œè®¾ç½® Repo çš„é…ç½®ã€‚è¿™ä¸ªé…ç½®å¯èƒ½åŒ…æ‹¬ä¸€äº›é€‰é¡¹ï¼Œå¦‚ "userAgent"ï¼Œç”¨äºæ ‡è¯† Repo çš„æ¥æºã€‚

4. åŠ è½½æ•°æ®ï¼šé€šè¿‡è°ƒç”¨ BlockStore å’Œ Repo ç±»çš„ `GetContent` æ–¹æ³•ï¼Œè·å–å¹¶åŠ è½½ Repo ä¸­çš„å†…å®¹ã€‚

5. è®¿é—®æ–‡ä»¶ç³»ç»Ÿï¼šé€šè¿‡è°ƒç”¨ BlockStore ç±»ä¸­çš„ `GetBlob` æ–¹æ³•ï¼Œè·å– Repo ä¸­çš„ä¸€ä¸ª Blobï¼ˆç±»ä¼¼äºæ–‡ä»¶ï¼‰ã€‚ç„¶åï¼Œä½¿ç”¨è¿™ä¸ª Blob ä¸­çš„ "Data" å­—æ®µæ¥è®¿é—®æ–‡ä»¶ç³»ç»Ÿï¼Œä¾‹å¦‚å†™å…¥æ–‡ä»¶ã€è¯»å–æ–‡ä»¶ç­‰ã€‚

6. éªŒè¯æ–‡ä»¶ç³»ç»Ÿï¼šé€šè¿‡è°ƒç”¨ thirdparty åŒ…ä¸­çš„ `VerifyFile` æ–¹æ³•ï¼ŒéªŒè¯æ–‡ä»¶ç³»ç»Ÿæ˜¯å¦ç¬¦åˆæŸç§å…±è¯†ï¼Œå¦‚é“¾å¼ HTTP  verifiable smart contractã€‚

7. é€šè¿‡ç¬¬ä¸‰æ–¹çš„èº«ä»½è®¤è¯ï¼šé€šè¿‡è°ƒç”¨ thirdparty åŒ…ä¸­çš„ `VerifySigned` æ–¹æ³•ï¼ŒéªŒè¯ä»£ç ç­¾åæ˜¯å¦æœ‰æ•ˆã€‚

8. é€šè¿‡ç¬¬ä¸‰æ–¹çš„æ•°æ®éªŒè¯ï¼šé€šè¿‡è°ƒç”¨ thirdparty åŒ…ä¸­çš„ `VerifyData` æ–¹æ³•ï¼ŒéªŒè¯æ•°æ®æ˜¯å¦ç¬¦åˆæŸç§å…±è¯†ã€‚

9. é€šè¿‡ç¬¬ä¸‰æ–¹è®¿é—® IPFSï¼šé€šè¿‡è°ƒç”¨ IPFS åŒ…ä¸­çš„ `kv.NewContext` æ–¹æ³•ï¼Œåˆ›å»ºä¸€ä¸ª IPFS çš„ "context"ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªä¸Šä¸‹æ–‡è°ƒç”¨ "boxo.Openç›®éŒ„" å’Œ "boxo.Openç›®éŒ„/default" æ–¹æ³•ï¼Œè®¿é—® IPFS çš„å†…å®¹ã€‚

10. æ”¯æŒç¦»çº¿ç¼–å†™æ–‡ä»¶ï¼šé€šè¿‡æ·»åŠ ä¸€ä¸ª `OfflineWrite` é…ç½®é€‰é¡¹ï¼Œå®ç° Offline æ¨¡å¼ï¼Œå³å¯ä»¥å°†æœ¬åœ°æ–‡ä»¶å†™å…¥ IPFS çš„å†…å®¹ã€‚


```
package node

import (
	blockstore "github.com/ipfs/boxo/blockstore"
	"github.com/ipfs/go-datastore"
	config "github.com/ipfs/kubo/config"
	"go.uber.org/fx"

	"github.com/ipfs/boxo/filestore"
	"github.com/ipfs/kubo/core/node/helpers"
	"github.com/ipfs/kubo/repo"
	"github.com/ipfs/kubo/thirdparty/verifbs"
)

// RepoConfig loads configuration from the repo
```

æ­¤ä»£ç å®šä¹‰äº†ä¸‰ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«ä½œç”¨å¦‚ä¸‹ï¼š

1. `RepoConfig`ï¼šè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ª `repo` å¯¹è±¡ï¼Œå¹¶è¿”å›ä¸€ä¸ª `Config` å¯¹è±¡å’Œä¸€ä¸ªé”™è¯¯ã€‚`Config` å¯¹è±¡è¡¨ç¤º `repo` çš„é…ç½®ï¼ŒåŒ…æ‹¬å¦‚ä½•ä¸å®¢æˆ·ç«¯è¿›è¡Œäº¤äº’ã€å¦‚ä½•ä¸åç«¯æœåŠ¡å™¨è¿›è¡Œäº¤äº’ä»¥åŠå¦‚ä½•å¯ç”¨åŠ å¯†ç­‰ã€‚

2. `Datastore`ï¼šè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ª `repo` å¯¹è±¡ï¼Œå¹¶è¿”å›ä¸€ä¸ª `datastore.Datastore` å¯¹è±¡ã€‚`Datastore` å‡½æ•°ç”¨äºä¸æœ¬åœ°æˆ–è¿œç¨‹æ•°æ®å­˜å‚¨è¿›è¡Œäº¤äº’ï¼Œå¹¶æä¾›ä¸€äº›é«˜çº§åŠŸèƒ½ï¼Œå¦‚äº‹åŠ¡ã€æ•°æ®ç¼“å­˜ç­‰ã€‚

3. `BaseBlockstoreCtor`ï¼šè¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ª `cacheOpts` å¯¹è±¡ï¼Œä¸€ä¸ª `nilRepo` æ ‡å¿—å’Œä¸€ä¸ª `hashOnRead` å¸ƒå°”å€¼ã€‚å®ƒåˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ `Blockstore` å‡½æ•°ï¼Œè¯¥å‡½æ•°ä½¿ç”¨æä¾›çš„ `datastore` å¯¹è±¡ã€`cacheOpts` å’Œ `hashOnRead` å‚æ•°ã€‚`BaseBlockstoreCtor` å‡½æ•°çš„ä½œç”¨æ˜¯åœ¨ `Blockstore` å’Œ `Datastore` å‡½æ•°çš„åŸºç¡€ä¸Šï¼Œè‡ªå®šä¹‰ä¸€ä¸ªæ›´é«˜çº§çš„ `Blockstore` å‡½æ•°ã€‚


```
func RepoConfig(repo repo.Repo) (*config.Config, error) {
	cfg, err := repo.Config()
	return cfg, err
}

// Datastore provides the datastore
func Datastore(repo repo.Repo) datastore.Datastore {
	return repo.Datastore()
}

// BaseBlocks is the lower level blockstore without GC or Filestore layers
type BaseBlocks blockstore.Blockstore

// BaseBlockstoreCtor creates cached blockstore backed by the provided datastore
func BaseBlockstoreCtor(cacheOpts blockstore.CacheOpts, nilRepo bool, hashOnRead bool) func(mctx helpers.MetricsCtx, repo repo.Repo, lc fx.Lifecycle) (bs BaseBlocks, err error) {
	return func(mctx helpers.MetricsCtx, repo repo.Repo, lc fx.Lifecycle) (bs BaseBlocks, err error) {
		// hash security
		bs = blockstore.NewBlockstore(repo.Datastore())
		bs = &verifbs.VerifBS{Blockstore: bs}

		if !nilRepo {
			bs, err = blockstore.CachedBlockstore(helpers.LifecycleCtx(mctx, lc), bs, cacheOpts)
			if err != nil {
				return nil, err
			}
		}

		bs = blockstore.NewIdStore(bs)

		if hashOnRead { // TODO: review: this is how it was done originally, is there a reason we can't just pass this directly?
			bs.HashOnRead(true)
		}

		return
	}
}

```

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨Goè¯­è¨€ç¼–å†™çš„å—å­˜å‚¨å™¨ç±»ï¼Œå…¶ä¸­GcBlockstoreCtorå‡½æ•°ä½¿ç”¨GCå’ŒFileStoreå±‚æ¥å°è£…å—å­˜å‚¨å™¨ã€‚è¯¥å‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„GCå—å­˜å‚¨å™¨å’Œä¸€ä¸ªGCLockerå¯¹è±¡ï¼Œç„¶åå°†å—å­˜å‚¨å™¨è®¾ç½®ä¸ºGcBlockstoreå’ŒFileStoreçš„ç»„åˆã€‚

GcBlockstoreCtorå‡½æ•°é¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªGCLockerç±»å‹å˜é‡gclockerï¼Œä»¥åŠä¸€ä¸ªGCBlockstoreç±»å‹å˜é‡gcbsã€‚ç„¶åï¼Œä½¿ç”¨NewGCLockerå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„GCå—å­˜å‚¨å™¨ã€‚æ¥ä¸‹æ¥ï¼Œä½¿ç”¨NewGCBlockstoreå‡½æ•°åˆ›å»ºä¸€ä¸ªGCBlockstoreå¯¹è±¡ï¼Œä½¿ç”¨gclockerä½œä¸ºGCBlockstoreçš„åº•å±‚å—å­˜å‚¨å™¨ã€‚æœ€åï¼Œå°†åˆ›å»ºçš„GCBlockstoreå¯¹è±¡å­˜å‚¨åˆ°å—å­˜å‚¨å™¨ä¸­ï¼Œå¹¶è¿”å›è¯¥å—å­˜å‚¨å™¨ã€‚

FilestoreBlockstoreCtorå‡½æ•°ä½¿ç”¨NewFilestoreå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„FileStoreå¯¹è±¡ï¼Œä½¿ç”¨NewGCBlockstoreå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„GCBlockstoreå¯¹è±¡ï¼Œä½¿ç”¨fstoreçš„åº•å±‚å—å­˜å‚¨å™¨ï¼Œå¹¶ä½¿ç”¨repoçš„FileManagerå‡½æ•°è®¾ç½®å—å­˜å‚¨å™¨çš„ç±»å‹ä¸ºrepo.ç„¶åï¼Œä½¿ç”¨NewGCLockerå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„GCå—å­˜å‚¨å™¨å¯¹è±¡ã€‚æ¥ä¸‹æ¥ï¼Œä½¿ç”¨filestore.NewFilestoreå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„FileStoreå¯¹è±¡ï¼Œå¹¶å°†å…¶å­˜å‚¨åˆ°GCBlockstoreçš„åº•å±‚å—å­˜å‚¨å™¨ä¸­ã€‚æœ€åï¼Œä½¿ç”¨NewGCLockerå‡½æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„GCå—å­˜å‚¨å™¨å¯¹è±¡ï¼Œå¹¶å°†å…¶ä¸FileStoreå¯¹è±¡ä¸€èµ·è¿”å›ã€‚


```
// GcBlockstoreCtor wraps the base blockstore with GC and Filestore layers
func GcBlockstoreCtor(bb BaseBlocks) (gclocker blockstore.GCLocker, gcbs blockstore.GCBlockstore, bs blockstore.Blockstore) {
	gclocker = blockstore.NewGCLocker()
	gcbs = blockstore.NewGCBlockstore(bb, gclocker)

	bs = gcbs
	return
}

// GcBlockstoreCtor wraps GcBlockstore and adds Filestore support
func FilestoreBlockstoreCtor(repo repo.Repo, bb BaseBlocks) (gclocker blockstore.GCLocker, gcbs blockstore.GCBlockstore, bs blockstore.Blockstore, fstore *filestore.Filestore) {
	gclocker = blockstore.NewGCLocker()

	// hash security
	fstore = filestore.NewFilestore(bb, repo.FileManager())
	gcbs = blockstore.NewGCBlockstore(fstore, gclocker)
	gcbs = &verifbs.VerifBSGC{GCBlockstore: gcbs}

	bs = gcbs
	return
}

```

# `/opt/kubo/core/node/helpers/helpers.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º "helpers" çš„åŒ…ï¼Œå…¶ä¸­åŒ…å«äº†ä¸€äº›ä¸ä¸Šä¸‹æ–‡å’Œå–æ¶ˆä¸Šä¸‹æ–‡ç›¸å…³çš„å‡½æ•°ã€‚

é¦–å…ˆï¼Œå®ƒå¯¼å…¥äº† "context" å’Œ "go.uber.org/fx" ä¸¤ä¸ªåŒ…ã€‚ç„¶åï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º "MetricsCtx" çš„ç±»å‹ï¼Œå®ƒä»£è¡¨ä¸€ä¸ªä¸Šä¸‹æ–‡ã€‚

æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º "LifecycleCtx" çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªåä¸º "mctx" çš„ MetricsCtx ç±»å‹çš„ä¸Šä¸‹æ–‡å’Œä¸€ä¸ªåä¸º "lc" çš„ä¸Šä¸‹æ–‡çš„ç”Ÿå‘½å‘¨æœŸå‡½æ•°ä½œä¸ºå‚æ•°ã€‚

è¯¥å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªåä¸º "ctx" çš„ä¸Šä¸‹æ–‡ï¼Œè¯¥ä¸Šä¸‹æ–‡å°†åœ¨ "mctx" å’Œ "lc" çš„ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸå†…ä¸€ç›´ä¿ç•™ã€‚ç„¶åï¼Œè¯¥å‡½æ•°ä½¿ç”¨ "context.WithCancel" å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡ï¼Œè¯¥ä¸Šä¸‹æ–‡ä¼šåœ¨ "mctx" çš„ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸç»“æŸåè¢«å–æ¶ˆã€‚

æ¥ä¸‹æ¥ï¼Œè¯¥å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªåä¸º "lc.Append" çš„å‡½æ•°ï¼Œå®ƒä¼šå°† "OnStop" äº‹ä»¶çš„å›è°ƒå‡½æ•°æ·»åŠ åˆ° "lc" çš„ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸå†…ã€‚è¿™ä¸ªäº‹ä»¶çš„å›è°ƒå‡½æ•°ä¼šåœ¨ "lc" çš„ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸç»“æŸæ—¶æ‰§è¡Œï¼Œå®ƒä¼šæ‰§è¡Œä¸€æ¬¡ "lc" ä¸Šä¸‹æ–‡çš„ "OnStop" äº‹ä»¶ã€‚

æœ€åï¼Œè¯¥å‡½æ•°è¿”å›ä¸Šä¸‹æ–‡ã€‚


```
package helpers

import (
	"context"

	"go.uber.org/fx"
)

type MetricsCtx context.Context

// LifecycleCtx creates a context which will be cancelled when lifecycle stops
//
// This is a hack which we need because most of our services use contexts in a
// wrong way
func LifecycleCtx(mctx MetricsCtx, lc fx.Lifecycle) context.Context {
	ctx, cancel := context.WithCancel(mctx)
	lc.Append(fx.Hook{
		OnStop: func(_ context.Context) error {
			cancel()
			return nil
		},
	})
	return ctx
}

```

# `/opt/kubo/core/node/libp2p/addrs.go`

è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º AddrFilters çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²æ•°ç»„ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå¹¶è¿”å›ä¸€ä¸ª Ma.Filters ç±»å‹çš„å‡½æ•°æŒ‡é’ˆã€Libp2pOpts ç±»å‹çš„é€‰é¡¹å’Œé”™è¯¯ã€‚

å‡½æ•°çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ª Ma.Filters ç±»å‹çš„è¿‡æ»¤å™¨ï¼Œç”¨äºæ ¹æ®ä¼ å…¥çš„åœ°å€è¿‡æ»¤å™¨é…ç½®ã€‚å®ƒé€šè¿‡ä»¥ä¸‹æ­¥éª¤åˆ›å»ºè¿‡æ»¤å™¨ï¼š

1. æ ¹æ®ä¼ å…¥çš„åœ°å€è¿‡æ»¤å™¨é…ç½®åˆ›å»ºä¸€ä¸ª Ma.Filters ç±»å‹çš„è¿‡æ»¤å™¨ã€‚
2. ä½¿ç”¨ libp2p.ConnectionGater å‡½æ•°å¯¹ä¼ å…¥çš„åœ°å€è¿‡æ»¤å™¨è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ä¾¿å¯ä»¥æ­£ç¡®åœ°ä¸ libp2p.PeerConnection é€šä¿¡ã€‚
3. éå†ä¼ å…¥çš„åœ°å€åˆ—è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªåœ°å€åˆ›å»ºä¸€ä¸ª Ma.Mask ç±»å‹çš„è¿‡æ»¤å™¨ã€‚
4. å°†åˆ›å»ºçš„è¿‡æ»¤å™¨æ·»åŠ åˆ° ma.Filters ç±»å‹çš„è¿‡æ»¤å™¨ä¸­ï¼Œå¹¶ä½¿ç”¨ ma.ActionDeny æ“ä½œå°†å…¶è®¾ç½®ä¸ºæ‹’ç»æ‰€æœ‰åŒ¹é…çš„æµé‡ã€‚
5. è¿”å›åˆšåˆšåˆ›å»ºçš„ ma.Filters ç±»å‹çš„è¿‡æ»¤å™¨ï¼Œé€‰é¡¹å’Œé”™è¯¯ã€‚

æœ€åï¼Œå‡½æ•°å¯ä»¥åœ¨éœ€è¦æ—¶åŠ¨æ€åœ°ä¿®æ”¹å…¶é…ç½®ï¼Œé€šè¿‡è°ƒç”¨ AddrFilters æ¥æ·»åŠ æ–°çš„åœ°å€è¿‡æ»¤å™¨ã€‚


```
package libp2p

import (
	"fmt"

	"github.com/libp2p/go-libp2p"
	p2pbhost "github.com/libp2p/go-libp2p/p2p/host/basic"
	ma "github.com/multiformats/go-multiaddr"
	mamask "github.com/whyrusleeping/multiaddr-filter"
)

func AddrFilters(filters []string) func() (*ma.Filters, Libp2pOpts, error) {
	return func() (filter *ma.Filters, opts Libp2pOpts, err error) {
		filter = ma.NewFilters()
		opts.Opts = append(opts.Opts, libp2p.ConnectionGater((*filtersConnectionGater)(filter)))
		for _, s := range filters {
			f, err := mamask.NewMask(s)
			if err != nil {
				return filter, opts, fmt.Errorf("incorrectly formatted address filter in config: %s", s)
			}
			filter.AddFilter(*f, ma.ActionDeny)
		}
		return filter, opts, nil
	}
}

```

This is a JavaScript function that seems to be part of a smart contract on the Ethereum blockchain. It appears to be a method for adding a user to a "no-announce" list, which appears to be a list of addresses that should not be included in the user'sä¸‹å» bundles.

The function takes in an array of address literals (i.e. strings) and returns an array of address literals that have been added to the no-announce list. It does this by first checking if the address is in the no-announce list using a simple if-else statement, and then using a multã„ãŸãƒ©ã‚¤ãƒ³è¡€ç—‡æ»¤ okayæ­£äº¤çƒŸé›¾ä¿¡å·ä»æ“ä½œ Ma å¯¹åœ°å€è¿›è¡ŒBLOCK æ“ä½œï¼Œå¯¹ address è¿›è¡Œæœ‰æ•ˆæ€§æ£€æŸ¥ã€‚

å¦‚æœ address ä¸åœ¨ no-announce list ä¸­ï¼Œåˆ™æ·»åŠ åˆ°è¾“å‡ºçš„ä¸€è¡Œã€‚

åœ¨å‡½æ•°ä¸­ï¼Œ AppendAnnounce å‡½æ•°ä¼¼ä¹æ˜¯åœ¨è°ƒç”¨è¿™å¼ è‡ªèº«è½¬ç§»çš„å‡½æ•°ï¼Œä½†æ˜¯å¤±è´¥äº†ï¼Œæ‰€ä»¥æ‰åœ¨é—®é¢˜æè¿°ä¸­æåˆ°ã€‚


```
func makeAddrsFactory(announce []string, appendAnnouce []string, noAnnounce []string) (p2pbhost.AddrsFactory, error) {
	var err error                     // To assign to the slice in the for loop
	existing := make(map[string]bool) // To avoid duplicates

	annAddrs := make([]ma.Multiaddr, len(announce))
	for i, addr := range announce {
		annAddrs[i], err = ma.NewMultiaddr(addr)
		if err != nil {
			return nil, err
		}
		existing[addr] = true
	}

	var appendAnnAddrs []ma.Multiaddr
	for _, addr := range appendAnnouce {
		if existing[addr] {
			// skip AppendAnnounce that is on the Announce list already
			continue
		}
		appendAddr, err := ma.NewMultiaddr(addr)
		if err != nil {
			return nil, err
		}
		appendAnnAddrs = append(appendAnnAddrs, appendAddr)
	}

	filters := ma.NewFilters()
	noAnnAddrs := map[string]bool{}
	for _, addr := range noAnnounce {
		f, err := mamask.NewMask(addr)
		if err == nil {
			filters.AddFilter(*f, ma.ActionDeny)
			continue
		}
		maddr, err := ma.NewMultiaddr(addr)
		if err != nil {
			return nil, err
		}
		noAnnAddrs[string(maddr.Bytes())] = true
	}

	return func(allAddrs []ma.Multiaddr) []ma.Multiaddr {
		var addrs []ma.Multiaddr
		if len(annAddrs) > 0 {
			addrs = annAddrs
		} else {
			addrs = allAddrs
		}
		addrs = append(addrs, appendAnnAddrs...)

		var out []ma.Multiaddr
		for _, maddr := range addrs {
			// check for exact matches
			ok := noAnnAddrs[string(maddr.Bytes())]
			// check for /ipcidr matches
			if !ok && !filters.AddrBlocked(maddr) {
				out = append(out, maddr)
			}
		}
		return out
	}, nil
}

```

è¿™ä¸¤ä¸ªå‡½æ•°çš„ä¸»è¦ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªåä¸º"addrsFactory"çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ä¸‰ä¸ªå‚æ•°ï¼šannounceã€appendAnnounceå’ŒnoAnnounceï¼Œå®ƒä»¬éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„æ•°ç»„ã€‚

ç¬¬ä¸€ä¸ªå‡½æ•° AddrsFactory çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªæ¥å—ä¸¤ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„æ•°ç»„å’Œç¬¬ä¸‰ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„æ•°ç»„çš„å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªæ¥å—ä¸¤ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„å˜é‡optså’Œä¸€ä¸ªé”™è¯¯ç±»å‹çš„å˜é‡errã€‚å‡½æ•°å†…éƒ¨è°ƒç”¨äº† makeAddrsFactory å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯announceã€appendAnnounceå’ŒnoAnnounceï¼Œå®ƒä»¬éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„æ•°ç»„ã€‚

å¦‚æœå‡½æ•°å†…éƒ¨ makeAddrsFactory å‡½æ•°æ­£å¸¸è¿”å›ï¼Œé‚£ä¹ˆ AddrsFactory å‡½æ•°å°†è¿”å›ä¸€ä¸ªæ¥å—ä¸¤ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„å˜é‡optså’Œä¸€ä¸ªé”™è¯¯ç±»å‹çš„å˜é‡errã€‚å¦‚æœå‡½æ•°å†…éƒ¨ makeAddrsFactory å‡½æ•°å‡ºç°é”™è¯¯ï¼Œé‚£ä¹ˆ AddrsFactory å‡½æ•°å°†è¿”å›ä¸€ä¸ªæ¥å—ä¸¤ä¸ªç©ºå­—ç¬¦ä¸²ç±»å‹çš„å˜é‡optså’Œä¸€ä¸ªé”™è¯¯ç±»å‹çš„å˜é‡errã€‚

ç¬¬äºŒä¸ªå‡½æ•° ListenOn çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„æ•°ç»„å’Œä¸€ä¸ªç©ºå­—ç¬¦ä¸²ç±»å‹çš„å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„å˜é‡optså’Œä¸€ä¸ªé”™è¯¯ç±»å‹çš„å˜é‡errã€‚å‡½æ•°å†…éƒ¨è°ƒç”¨äº† Libp2pOpts å’Œ ListenOn å‡½æ•°ï¼Œåˆ†åˆ«è¿”å›ä¸€ä¸ªæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„é€‰é¡¹ç±»å‹å’Œä¸€ä¸ªç©ºå­—ç¬¦ä¸²ç±»å‹çš„å‡½æ•°ï¼Œå¹¶å°†å®ƒä»¬ç»„åˆåœ¨ä¸€èµ·ï¼Œæœ€ç»ˆè¿”å›ä¸€ä¸ªæ¥å—ä¸¤ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„é€‰é¡¹ç±»å‹å’Œä¸€ä¸ªé”™è¯¯ç±»å‹çš„å˜é‡errçš„å‡½æ•°ã€‚


```
func AddrsFactory(announce []string, appendAnnouce []string, noAnnounce []string) func() (opts Libp2pOpts, err error) {
	return func() (opts Libp2pOpts, err error) {
		addrsFactory, err := makeAddrsFactory(announce, appendAnnouce, noAnnounce)
		if err != nil {
			return opts, err
		}
		opts.Opts = append(opts.Opts, libp2p.AddrsFactory(addrsFactory))
		return
	}
}

func ListenOn(addresses []string) interface{} {
	return func() (opts Libp2pOpts) {
		return Libp2pOpts{
			Opts: []libp2p.Option{
				libp2p.ListenAddrStrings(addresses...),
			},
		}
	}
}

```